{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59156,"databundleVersionId":13874099,"sourceType":"competition"},{"sourceId":262477103,"sourceType":"kernelVersion"},{"sourceId":279806245,"sourceType":"kernelVersion"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q --no-index --find-links=/kaggle/input/mabe-package xgboost==3.1.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T01:29:17.400604Z","iopub.execute_input":"2025-11-22T01:29:17.400922Z","iopub.status.idle":"2025-11-22T01:29:34.595264Z","shell.execute_reply.started":"2025-11-22T01:29:17.400896Z","shell.execute_reply":"2025-11-22T01:29:34.594050Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import datetime\nimport gc\nimport itertools\nimport json\nimport re\nimport sys\nimport time\nimport traceback\nfrom collections import defaultdict\nfrom pathlib import Path\n\nimport joblib\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport xgboost as xgb\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom tqdm.auto import tqdm\n\nsys.path.append(\"/kaggle/usr/lib/mabe-f-beta\")\nfrom metric import score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T01:29:34.597236Z","iopub.execute_input":"2025-11-22T01:29:34.597586Z","iopub.status.idle":"2025-11-22T01:29:43.573666Z","shell.execute_reply.started":"2025-11-22T01:29:34.597557Z","shell.execute_reply":"2025-11-22T01:29:43.572577Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# const\nINPUT_DIR = Path(\"/kaggle/input/MABe-mouse-behavior-detection\")\nTRAIN_TRACKING_DIR = INPUT_DIR / \"train_tracking\"\nTRAIN_ANNOTATION_DIR = INPUT_DIR / \"train_annotation\"\nTEST_TRACKING_DIR = INPUT_DIR / \"test_tracking\"\n\nWORKING_DIR = Path(\"/kaggle/working\")\n\nINDEX_COLS = [\n    \"video_id\",\n    \"agent_mouse_id\",\n    \"target_mouse_id\",\n    \"video_frame\",\n]\n\nBODY_PARTS = [\n    \"ear_left\",\n    \"ear_right\",\n    \"nose\",\n    \"neck\",\n    \"body_center\",\n    \"lateral_left\",\n    \"lateral_right\",\n    \"hip_left\",\n    \"hip_right\",\n    \"tail_base\",\n    \"tail_tip\",\n]\n\nSELF_BEHAVIORS = [\n    \"biteobject\",\n    \"climb\",\n    \"dig\",\n    \"exploreobject\",\n    \"freeze\",\n    \"genitalgroom\",\n    \"huddle\",\n    \"rear\",\n    \"rest\",\n    \"run\",\n    \"selfgroom\",\n]\n\nPAIR_BEHAVIORS = [\n    \"allogroom\",\n    \"approach\",\n    \"attack\",\n    \"attemptmount\",\n    \"avoid\",\n    \"chase\",\n    \"chaseattack\",\n    \"defend\",\n    \"disengage\",\n    \"dominance\",\n    \"dominancegroom\",\n    \"dominancemount\",\n    \"ejaculate\",\n    \"escape\",\n    \"flinch\",\n    \"follow\",\n    \"intromit\",\n    \"mount\",\n    \"reciprocalsniff\",\n    \"shepherd\",\n    \"sniff\",\n    \"sniffbody\",\n    \"sniffface\",\n    \"sniffgenital\",\n    \"submit\",\n    \"tussle\",\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T01:29:43.574631Z","iopub.execute_input":"2025-11-22T01:29:43.575302Z","iopub.status.idle":"2025-11-22T01:29:43.582921Z","shell.execute_reply.started":"2025-11-22T01:29:43.575274Z","shell.execute_reply":"2025-11-22T01:29:43.582086Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# read data\ntrain_dataframe = pl.read_csv(INPUT_DIR / \"train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T01:29:43.584846Z","iopub.execute_input":"2025-11-22T01:29:43.585143Z","iopub.status.idle":"2025-11-22T01:29:43.785790Z","shell.execute_reply.started":"2025-11-22T01:29:43.585121Z","shell.execute_reply":"2025-11-22T01:29:43.784697Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Data Processing","metadata":{}},{"cell_type":"markdown","source":"## Pre-preparation","metadata":{}},{"cell_type":"code","source":"# preprocess behavior labels\ntrain_behavior_dataframe = (\n    train_dataframe.filter(pl.col(\"behaviors_labeled\").is_not_null())\n    .select(\n        pl.col(\"lab_id\"),\n        pl.col(\"video_id\"),\n        pl.col(\"behaviors_labeled\").map_elements(eval, return_dtype=pl.List(pl.Utf8)).alias(\"behaviors_labeled_list\"),\n    )\n    .explode(\"behaviors_labeled_list\")\n    .rename({\"behaviors_labeled_list\": \"behaviors_labeled_element\"})\n    .select(\n        pl.col(\"lab_id\"),\n        pl.col(\"video_id\"),\n        pl.col(\"behaviors_labeled_element\").str.split(\",\").list[0].str.replace_all(\"'\", \"\").alias(\"agent\"),\n        pl.col(\"behaviors_labeled_element\").str.split(\",\").list[1].str.replace_all(\"'\", \"\").alias(\"target\"),\n        pl.col(\"behaviors_labeled_element\").str.split(\",\").list[2].str.replace_all(\"'\", \"\").alias(\"behavior\"),\n    )\n)\n\ntrain_self_behavior_dataframe = train_behavior_dataframe.filter(pl.col(\"behavior\").is_in(SELF_BEHAVIORS))\ntrain_pair_behavior_dataframe = train_behavior_dataframe.filter(pl.col(\"behavior\").is_in(PAIR_BEHAVIORS))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T01:29:43.786762Z","iopub.execute_input":"2025-11-22T01:29:43.787115Z","iopub.status.idle":"2025-11-22T01:29:44.082317Z","shell.execute_reply.started":"2025-11-22T01:29:43.787084Z","shell.execute_reply":"2025-11-22T01:29:44.081371Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_self_behavior_dataframe.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T01:29:44.083257Z","iopub.execute_input":"2025-11-22T01:29:44.083616Z","iopub.status.idle":"2025-11-22T01:29:44.101496Z","shell.execute_reply.started":"2025-11-22T01:29:44.083585Z","shell.execute_reply":"2025-11-22T01:29:44.100557Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"shape: (5, 5)\n┌────────────────┬───────────┬────────┬────────┬──────────┐\n│ lab_id         ┆ video_id  ┆ agent  ┆ target ┆ behavior │\n│ ---            ┆ ---       ┆ ---    ┆ ---    ┆ ---      │\n│ str            ┆ i64       ┆ str    ┆ str    ┆ str      │\n╞════════════════╪═══════════╪════════╪════════╪══════════╡\n│ AdaptableSnail ┆ 44566106  ┆ mouse1 ┆ self   ┆ rear     │\n│ AdaptableSnail ┆ 44566106  ┆ mouse2 ┆ self   ┆ rear     │\n│ AdaptableSnail ┆ 44566106  ┆ mouse3 ┆ self   ┆ rear     │\n│ AdaptableSnail ┆ 44566106  ┆ mouse4 ┆ self   ┆ rear     │\n│ AdaptableSnail ┆ 143861384 ┆ mouse1 ┆ self   ┆ rear     │\n└────────────────┴───────────┴────────┴────────┴──────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>lab_id</th><th>video_id</th><th>agent</th><th>target</th><th>behavior</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;AdaptableSnail&quot;</td><td>44566106</td><td>&quot;mouse1&quot;</td><td>&quot;self&quot;</td><td>&quot;rear&quot;</td></tr><tr><td>&quot;AdaptableSnail&quot;</td><td>44566106</td><td>&quot;mouse2&quot;</td><td>&quot;self&quot;</td><td>&quot;rear&quot;</td></tr><tr><td>&quot;AdaptableSnail&quot;</td><td>44566106</td><td>&quot;mouse3&quot;</td><td>&quot;self&quot;</td><td>&quot;rear&quot;</td></tr><tr><td>&quot;AdaptableSnail&quot;</td><td>44566106</td><td>&quot;mouse4&quot;</td><td>&quot;self&quot;</td><td>&quot;rear&quot;</td></tr><tr><td>&quot;AdaptableSnail&quot;</td><td>143861384</td><td>&quot;mouse1&quot;</td><td>&quot;self&quot;</td><td>&quot;rear&quot;</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"train_pair_behavior_dataframe.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T01:29:44.102466Z","iopub.execute_input":"2025-11-22T01:29:44.102925Z","iopub.status.idle":"2025-11-22T01:29:44.124756Z","shell.execute_reply.started":"2025-11-22T01:29:44.102894Z","shell.execute_reply":"2025-11-22T01:29:44.123890Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"shape: (5, 5)\n┌────────────────┬──────────┬────────┬────────┬─────────────┐\n│ lab_id         ┆ video_id ┆ agent  ┆ target ┆ behavior    │\n│ ---            ┆ ---      ┆ ---    ┆ ---    ┆ ---         │\n│ str            ┆ i64      ┆ str    ┆ str    ┆ str         │\n╞════════════════╪══════════╪════════╪════════╪═════════════╡\n│ AdaptableSnail ┆ 44566106 ┆ mouse1 ┆ mouse2 ┆ approach    │\n│ AdaptableSnail ┆ 44566106 ┆ mouse1 ┆ mouse2 ┆ attack      │\n│ AdaptableSnail ┆ 44566106 ┆ mouse1 ┆ mouse2 ┆ avoid       │\n│ AdaptableSnail ┆ 44566106 ┆ mouse1 ┆ mouse2 ┆ chase       │\n│ AdaptableSnail ┆ 44566106 ┆ mouse1 ┆ mouse2 ┆ chaseattack │\n└────────────────┴──────────┴────────┴────────┴─────────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>lab_id</th><th>video_id</th><th>agent</th><th>target</th><th>behavior</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;AdaptableSnail&quot;</td><td>44566106</td><td>&quot;mouse1&quot;</td><td>&quot;mouse2&quot;</td><td>&quot;approach&quot;</td></tr><tr><td>&quot;AdaptableSnail&quot;</td><td>44566106</td><td>&quot;mouse1&quot;</td><td>&quot;mouse2&quot;</td><td>&quot;attack&quot;</td></tr><tr><td>&quot;AdaptableSnail&quot;</td><td>44566106</td><td>&quot;mouse1&quot;</td><td>&quot;mouse2&quot;</td><td>&quot;avoid&quot;</td></tr><tr><td>&quot;AdaptableSnail&quot;</td><td>44566106</td><td>&quot;mouse1&quot;</td><td>&quot;mouse2&quot;</td><td>&quot;chase&quot;</td></tr><tr><td>&quot;AdaptableSnail&quot;</td><td>44566106</td><td>&quot;mouse1&quot;</td><td>&quot;mouse2&quot;</td><td>&quot;chaseattack&quot;</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"%%writefile self_features.py\n\ndef make_self_features(\n    metadata: dict,\n    tracking: pl.DataFrame,\n) -> pl.DataFrame:\n    def body_parts_distance(body_part_1, body_part_2):\n        # The distance between each agent bodypart\n        assert body_part_1 in BODY_PARTS\n        assert body_part_2 in BODY_PARTS\n        return (\n            (pl.col(f\"agent_x_{body_part_1}\") - pl.col(f\"agent_x_{body_part_2}\")).pow(2)\n            + (pl.col(f\"agent_y_{body_part_1}\") - pl.col(f\"agent_y_{body_part_2}\")).pow(2)\n        ).sqrt() / metadata[\"pix_per_cm_approx\"]\n\n    def body_part_speed(body_part, period_ms):\n        # Approximate velocity of the bodypart (cm/s)\n        assert body_part in BODY_PARTS\n        window_frames = max(1, int(round(period_ms * metadata[\"frames_per_second\"] / 1000.0)))\n        return (\n            ((pl.col(f\"agent_x_{body_part}\").diff()).pow(2) + (pl.col(f\"agent_y_{body_part}\").diff()).pow(2)).sqrt()\n            / metadata[\"pix_per_cm_approx\"]\n            * metadata[\"frames_per_second\"]\n        ).rolling_mean(window_size=window_frames, center=True)\n\n    def elongation():\n        d1 = body_parts_distance(\"nose\", \"tail_base\")\n        d2 = body_parts_distance(\"ear_left\", \"ear_right\")\n        return d1 / (d2 + 1e-06)\n\n    def body_angle():\n        v1x = pl.col(\"agent_x_nose\") - pl.col(\"agent_x_body_center\")\n        v1y = pl.col(\"agent_y_nose\") - pl.col(\"agent_y_body_center\")\n        v2x = pl.col(\"agent_x_tail_base\") - pl.col(\"agent_x_body_center\")\n        v2y = pl.col(\"agent_y_tail_base\") - pl.col(\"agent_y_body_center\")\n        return (v1x * v2x + v1y * v2y) / ((v1x.pow(2) + v1y.pow(2)).sqrt() * (v2x.pow(2) + v2y.pow(2)).sqrt() + 1e-06)\n\n    # number of detected mice\n    n_mice = (\n        (metadata[\"mouse1_strain\"] is not None)\n        + (metadata[\"mouse2_strain\"] is not None)\n        + (metadata[\"mouse3_strain\"] is not None)\n        + (metadata[\"mouse4_strain\"] is not None)\n    )\n    \n    start_frame = tracking.select(pl.col(\"video_frame\").min()).item()\n    end_frame = tracking.select(pl.col(\"video_frame\").max()).item()\n\n    result = []\n\n    pivot = tracking.pivot(\n        on=[\"bodypart\"],\n        index=[\"video_frame\", \"mouse_id\"],\n        values=[\"x\", \"y\"],\n    ).sort([\"mouse_id\", \"video_frame\"])\n    pivot_trackings = {mouse_id: pivot.filter(pl.col(\"mouse_id\") == mouse_id) for mouse_id in range(1, n_mice + 1)}\n\n    for agent_mouse_id in range(1, n_mice + 1):\n        result_element = pl.DataFrame(\n            {\n                \"video_id\": metadata[\"video_id\"],\n                \"agent_mouse_id\": agent_mouse_id,\n                \"target_mouse_id\": -1,\n                \"video_frame\": pl.arange(start_frame, end_frame + 1, eager=True),\n            },\n            schema={\n                \"video_id\": pl.Int32,\n                \"agent_mouse_id\": pl.Int8,\n                \"target_mouse_id\": pl.Int8,\n                \"video_frame\": pl.Int32,\n            },\n        )\n\n        pivot = pivot_trackings[agent_mouse_id].select(\n            pl.col(\"video_frame\"),\n            pl.from_epoch(\n                pl.col(\"video_frame\").truediv(metadata[\"frames_per_second\"]).mul(1_000_000),\n                time_unit=\"us\",\n            ).alias(\"timestamp\"),\n            pl.exclude(\"video_frame\").name.prefix(\"agent_\"),\n        )\n        columns = pivot.columns\n        pivot = pivot.with_columns(\n            *[pl.lit(None).cast(pl.Float32).alias(f\"agent_x_{bp}\") for bp in BODY_PARTS if f\"agent_x_{bp}\" not in columns],\n            *[pl.lit(None).cast(pl.Float32).alias(f\"agent_y_{bp}\") for bp in BODY_PARTS if f\"agent_y_{bp}\" not in columns],\n        )\n\n        features = pivot.with_columns(\n            pl.lit(agent_mouse_id).alias(\"agent_mouse_id\"),\n            pl.lit(-1).alias(\"target_mouse_id\"),\n        ).select(\n            pl.col(\"video_frame\"),\n            pl.col(\"agent_mouse_id\"),\n            pl.col(\"target_mouse_id\"),\n            *[\n                body_parts_distance(body_part_1, body_part_2).alias(f\"aa__{body_part_1}__{body_part_2}__distance\")\n                for body_part_1, body_part_2 in itertools.combinations(BODY_PARTS, 2)\n            ],\n            *[\n                body_part_speed(body_part, period_ms).alias(f\"agent__{body_part}__speed_{period_ms}ms\")\n                for body_part, period_ms in itertools.product([\"ear_left\", \"ear_right\", \"tail_base\"], [500, 1000, 2000])\n            ],\n            elongation().alias(\"agent__elongation\"),\n            body_angle().alias(\"agent__body_angle\"),\n        )\n\n        result_element = result_element.join(\n            features,\n            on=[\"video_frame\", \"agent_mouse_id\", \"target_mouse_id\"],\n            how=\"left\",\n        )\n        result.append(result_element)\n\n    return pl.concat(result, how=\"vertical\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T01:29:44.125773Z","iopub.execute_input":"2025-11-22T01:29:44.126043Z","iopub.status.idle":"2025-11-22T01:29:44.149920Z","shell.execute_reply.started":"2025-11-22T01:29:44.126015Z","shell.execute_reply":"2025-11-22T01:29:44.148949Z"}},"outputs":[{"name":"stdout","text":"Writing self_features.py\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"%%writefile pair_features.py\n\ndef make_pair_features(\n    metadata: dict,\n    tracking: pl.DataFrame,\n) -> pl.DataFrame:\n    def body_parts_distance(agent_or_target_1, body_part_1, agent_or_target_2, body_part_2):\n        # Distance of each bodypart between agent-target\n        assert agent_or_target_1 == \"agent\" or agent_or_target_1 == \"target\"\n        assert agent_or_target_2 == \"agent\" or agent_or_target_2 == \"target\"\n        assert body_part_1 in BODY_PARTS\n        assert body_part_2 in BODY_PARTS\n        return (\n            (pl.col(f\"{agent_or_target_1}_x_{body_part_1}\") - pl.col(f\"{agent_or_target_2}_x_{body_part_2}\")).pow(2)\n            + (pl.col(f\"{agent_or_target_1}_y_{body_part_1}\") - pl.col(f\"{agent_or_target_2}_y_{body_part_2}\")).pow(2)\n        ).sqrt() / metadata[\"pix_per_cm_approx\"]\n\n    def body_part_speed(agent_or_target, body_part, period_ms):\n        # # Approximate velocity of the bodypart (cm/s)\n        assert agent_or_target == \"agent\" or agent_or_target == \"target\"\n        assert body_part in BODY_PARTS\n        window_frames = max(1, int(round(period_ms * metadata[\"frames_per_second\"] / 1000.0)))\n        return (\n            (\n                (pl.col(f\"{agent_or_target}_x_{body_part}\").diff()).pow(2)\n                + (pl.col(f\"{agent_or_target}_y_{body_part}\").diff()).pow(2)\n            ).sqrt()\n            / metadata[\"pix_per_cm_approx\"]\n            * metadata[\"frames_per_second\"]\n        ).rolling_mean(window_size=window_frames, center=True)\n\n    def elongation(agent_or_target):\n        assert agent_or_target == \"agent\" or agent_or_target == \"target\"\n        d1 = body_parts_distance(agent_or_target, \"nose\", agent_or_target, \"tail_base\")\n        d2 = body_parts_distance(agent_or_target, \"ear_left\", agent_or_target, \"ear_right\")\n        return d1 / (d2 + 1e-06)\n\n    def body_angle(agent_or_target):\n        assert agent_or_target == \"agent\" or agent_or_target == \"target\"\n        v1x = pl.col(f\"{agent_or_target}_x_nose\") - pl.col(f\"{agent_or_target}_x_body_center\")\n        v1y = pl.col(f\"{agent_or_target}_y_nose\") - pl.col(f\"{agent_or_target}_y_body_center\")\n        v2x = pl.col(f\"{agent_or_target}_x_tail_base\") - pl.col(f\"{agent_or_target}_x_body_center\")\n        v2y = pl.col(f\"{agent_or_target}_y_tail_base\") - pl.col(f\"{agent_or_target}_y_body_center\")\n        return (v1x * v2x + v1y * v2y) / ((v1x.pow(2) + v1y.pow(2)).sqrt() * (v2x.pow(2) + v2y.pow(2)).sqrt() + 1e-06)\n\n    n_mice = (\n        (metadata[\"mouse1_strain\"] is not None)\n        + (metadata[\"mouse2_strain\"] is not None)\n        + (metadata[\"mouse3_strain\"] is not None)\n        + (metadata[\"mouse4_strain\"] is not None)\n    )\n    start_frame = tracking.select(pl.col(\"video_frame\").min()).item()\n    end_frame = tracking.select(pl.col(\"video_frame\").max()).item()\n\n    result = []\n\n    pivot = tracking.pivot(\n        on=[\"bodypart\"],\n        index=[\"video_frame\", \"mouse_id\"],\n        values=[\"x\", \"y\"],\n    ).sort([\"mouse_id\", \"video_frame\"])\n    pivot_trackings = {mouse_id: pivot.filter(pl.col(\"mouse_id\") == mouse_id) for mouse_id in range(1, n_mice + 1)}\n\n    for agent_mouse_id, target_mouse_id in itertools.permutations(range(1, n_mice + 1), 2):\n        result_element = pl.DataFrame(\n            {\n                \"video_id\": metadata[\"video_id\"],\n                \"agent_mouse_id\": agent_mouse_id,\n                \"target_mouse_id\": target_mouse_id,\n                \"video_frame\": pl.arange(start_frame, end_frame + 1, eager=True),\n            },\n            schema={\n                \"video_id\": pl.Int32,\n                \"agent_mouse_id\": pl.Int8,\n                \"target_mouse_id\": pl.Int8,\n                \"video_frame\": pl.Int32,\n            },\n        )\n\n        merged_pivot = (\n            pivot_trackings[agent_mouse_id]\n            .select(\n                pl.col(\"video_frame\"),\n                pl.exclude(\"video_frame\").name.prefix(\"agent_\"),\n            )\n            .join(\n                pivot_trackings[target_mouse_id].select(\n                    pl.col(\"video_frame\"),\n                    pl.exclude(\"video_frame\").name.prefix(\"target_\"),\n                ),\n                on=\"video_frame\",\n                how=\"inner\",\n            )\n            .with_columns(\n                pl.from_epoch(\n                    pl.col(\"video_frame\").truediv(metadata[\"frames_per_second\"]).mul(1_000_000),\n                    time_unit=\"us\",\n                ).alias(\"timestamp\"),\n            )\n        )\n        columns = merged_pivot.columns\n        merged_pivot = merged_pivot.with_columns(\n            *[pl.lit(None).cast(pl.Float32).alias(f\"agent_x_{bp}\") for bp in BODY_PARTS if f\"agent_x_{bp}\" not in columns],\n            *[pl.lit(None).cast(pl.Float32).alias(f\"agent_y_{bp}\") for bp in BODY_PARTS if f\"agent_y_{bp}\" not in columns],\n            *[pl.lit(None).cast(pl.Float32).alias(f\"target_x_{bp}\") for bp in BODY_PARTS if f\"target_x_{bp}\" not in columns],\n            *[pl.lit(None).cast(pl.Float32).alias(f\"target_y_{bp}\") for bp in BODY_PARTS if f\"target_y_{bp}\" not in columns],\n        )\n\n        features = merged_pivot.with_columns(\n            pl.lit(agent_mouse_id).alias(\"agent_mouse_id\"),\n            pl.lit(target_mouse_id).alias(\"target_mouse_id\"),\n        ).select(\n            pl.col(\"video_frame\"),\n            pl.col(\"agent_mouse_id\"),\n            pl.col(\"target_mouse_id\"),\n            *[\n                body_parts_distance(\"agent\", agent_body_part, \"target\", target_body_part).alias(\n                    f\"at__{agent_body_part}__{target_body_part}__distance\"\n                )\n                for agent_body_part, target_body_part in itertools.product(BODY_PARTS, repeat=2)\n            ],\n            *[\n                body_part_speed(\"agent\", body_part, period_ms).alias(f\"agent__{body_part}__speed_{period_ms}ms\")\n                for body_part, period_ms in itertools.product([\"ear_left\", \"ear_right\", \"tail_base\"], [500, 1000, 2000])\n            ],\n            *[\n                body_part_speed(\"target\", body_part, period_ms).alias(f\"target__{body_part}__speed_{period_ms}ms\")\n                for body_part, period_ms in itertools.product([\"ear_left\", \"ear_right\", \"tail_base\"], [500, 1000, 2000])\n            ],\n            elongation(\"agent\").alias(\"agent__elongation\"),\n            elongation(\"target\").alias(\"target__elongation\"),\n            body_angle(\"agent\").alias(\"agent__body_angle\"),\n            body_angle(\"target\").alias(\"target__body_angle\"),\n        )\n\n        result_element = result_element.join(\n            features,\n            on=[\"video_frame\", \"agent_mouse_id\", \"target_mouse_id\"],\n            how=\"left\",\n        )\n        result.append(result_element)\n\n    return pl.concat(result, how=\"vertical\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T01:29:44.151085Z","iopub.execute_input":"2025-11-22T01:29:44.151478Z","iopub.status.idle":"2025-11-22T01:29:44.179338Z","shell.execute_reply.started":"2025-11-22T01:29:44.151449Z","shell.execute_reply":"2025-11-22T01:29:44.177977Z"}},"outputs":[{"name":"stdout","text":"Writing pair_features.py\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"%run -i self_features.py\n%run -i pair_features.py\n\ndef process_video(row):\n    \"\"\"Process a single video to extract self and pair features.\"\"\"\n    lab_id = row[\"lab_id\"]\n    video_id = row[\"video_id\"]\n\n    tracking_path = TRAIN_TRACKING_DIR / f\"{lab_id}/{video_id}.parquet\"\n    tracking = pl.read_parquet(tracking_path)\n\n    self_features = make_self_features(metadata=row, tracking=tracking)\n    pair_features = make_pair_features(metadata=row, tracking=tracking)\n\n    self_features.write_parquet(WORKING_DIR / \"self_features\" / f\"{video_id}.parquet\")\n    pair_features.write_parquet(WORKING_DIR / \"pair_features\" / f\"{video_id}.parquet\")\n\n    return video_id\n\n\n# make data\n(WORKING_DIR / \"self_features\").mkdir(exist_ok=True, parents=True)\n(WORKING_DIR / \"pair_features\").mkdir(exist_ok=True, parents=True)\n\nrows = list(train_dataframe.filter(pl.col(\"behaviors_labeled\").is_not_null()).rows(named=True))\nresults = joblib.Parallel(n_jobs=-1, verbose=5)(joblib.delayed(process_video)(row) for row in rows) # 特徴量生成\nprint(f\"Processed {len(results)} videos successfully\")\n\ndel rows, results\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T01:29:44.182982Z","iopub.execute_input":"2025-11-22T01:29:44.183298Z","iopub.status.idle":"2025-11-22T01:35:26.799183Z","shell.execute_reply.started":"2025-11-22T01:29:44.183273Z","shell.execute_reply":"2025-11-22T01:35:26.798070Z"}},"outputs":[{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  warnings.warn(\n[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   19.5s\n[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  2.2min\n[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.6min\n[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  3.1min\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.6min\n[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  4.6min\n[Parallel(n_jobs=-1)]: Done 848 out of 848 | elapsed:  5.7min finished\n","output_type":"stream"},{"name":"stdout","text":"Processed 848 videos successfully\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"27"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def tune_threshold(oof_action, y_action):\n    thresholds = np.arange(0, 1.005, 0.005)\n    scores = [f1_score(y_action, (oof_action >= th), zero_division=0) for th in thresholds]\n    best_idx = np.argmax(scores)\n    return thresholds[best_idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T01:35:26.800286Z","iopub.execute_input":"2025-11-22T01:35:26.800636Z","iopub.status.idle":"2025-11-22T01:35:26.806799Z","shell.execute_reply.started":"2025-11-22T01:35:26.800613Z","shell.execute_reply":"2025-11-22T01:35:26.805816Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def train_validate(lab_id: str, behavior: str, indices: pl.DataFrame, features: pl.DataFrame, labels: pl.Series):\n    result_dir = WORKING_DIR / \"results\" / lab_id / behavior\n    result_dir.mkdir(exist_ok=True, parents=True)\n\n    if labels.sum() == 0:\n        with open(result_dir / \"f1.txt\", \"w\") as f:\n            f.write(\"0.0\\n\")\n        oof_prediction_dataframe = indices.with_columns(\n            pl.Series(\"fold\", [-1] * len(labels), dtype=pl.Int8),\n            pl.Series(\"prediction\", [0.0] * len(labels), dtype=pl.Float32),\n            pl.Series(\"predicted_label\", [0] * len(labels), dtype=pl.Int8),\n        )\n        oof_prediction_dataframe.write_parquet(result_dir / \"oof_predictions.parquet\")\n        return 0.0\n\n    folds = np.ones(len(labels), dtype=np.int8) * -1\n    oof_predictions = np.zeros(len(labels), dtype=np.float32)\n    oof_prediction_labels = np.zeros(len(labels), dtype=np.int8)\n\n    for fold, (train_idx, valid_idx) in enumerate(\n        StratifiedGroupKFold(n_splits=3, shuffle=True, random_state=42).split(\n            X=features,\n            y=labels,\n            groups=indices.get_column(\"video_id\"),\n        )\n    ):\n        result_dir_fold = result_dir / f\"fold_{fold}\"\n        result_dir_fold.mkdir(exist_ok=True, parents=True)\n\n        X_train = features[train_idx]\n        y_train = labels[train_idx]\n        X_valid = features[valid_idx]\n        y_valid = labels[valid_idx]\n\n        scale_pos_weight = (len(y_train) - y_train.sum()) / y_train.sum()\n\n        params = {\n            \"objective\": \"binary:logistic\",\n            \"eval_metric\": \"logloss\",\n            \"device\": \"cpu\",\n            \"tree_method\": \"hist\",\n            \"learning_rate\": 0.05,\n            \"max_depth\": 6,\n            \"min_child_weight\": 5,\n            \"subsample\": 0.8,\n            \"colsample_bytree\": 0.8,\n            \"scale_pos_weight\": scale_pos_weight,\n            \"max_bin\": 64,\n            \"seed\": 42,\n        }\n        dtrain = xgb.QuantileDMatrix(X_train, label=y_train, feature_names=features.columns, max_bin=64)\n        dvalid = xgb.DMatrix(X_valid, label=y_valid, feature_names=features.columns)\n\n        evals_result = {}\n        early_stopping_callback = xgb.callback.EarlyStopping(\n            rounds=10,\n            metric_name=\"logloss\",\n            data_name=\"valid\",\n            maximize=False,\n            save_best=True,\n        )\n        model = xgb.train(\n            params,\n            dtrain=dtrain,\n            num_boost_round=250,\n            evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n            callbacks=[early_stopping_callback],\n            evals_result=evals_result,\n            verbose_eval=0,\n        )\n\n        fold_predictions = model.predict(dvalid)\n\n        threshold = tune_threshold(fold_predictions, y_valid)\n        folds[valid_idx] = fold\n        oof_predictions[valid_idx] = fold_predictions\n        oof_prediction_labels[valid_idx] = (fold_predictions >= threshold).astype(np.int8)\n\n        # save results\n        model.save_model(result_dir_fold / \"model.json\")\n        with open(result_dir_fold / \"threshold.txt\", \"w\") as f:\n            f.write(f\"{threshold}\\n\")\n\n        xgb.plot_importance(model, max_num_features=20, importance_type=\"gain\", values_format=\"{v:.2f}\")\n        plt.tight_layout()\n        plt.savefig(result_dir_fold / \"feature_importance.png\")\n        plt.close()\n\n        lgb.plot_metric(evals_result, metric=\"logloss\")\n        plt.tight_layout()\n        plt.savefig(result_dir_fold / \"metric.png\")\n        plt.close()\n\n        gc.collect()\n\n    oof_prediction_dataframe = indices.with_columns(\n        pl.Series(\"fold\", folds, dtype=pl.Int8),\n        pl.Series(\"prediction\", oof_predictions, dtype=pl.Float32),\n        pl.Series(\"predicted_label\", oof_prediction_labels, dtype=pl.Int8),\n    )\n    f1 = f1_score(labels, oof_prediction_labels, zero_division=0)\n    with open(result_dir / \"f1.txt\", \"w\") as f:\n        f.write(f\"{f1}\\n\")\n\n    oof_prediction_dataframe.write_parquet(result_dir / \"oof_predictions.parquet\")\n\n    return f1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T01:35:26.807931Z","iopub.execute_input":"2025-11-22T01:35:26.808379Z","iopub.status.idle":"2025-11-22T01:35:26.839276Z","shell.execute_reply.started":"2025-11-22T01:35:26.808346Z","shell.execute_reply":"2025-11-22T01:35:26.837832Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"\"\"\"\nself features\n\"\"\"\ngroups = train_self_behavior_dataframe.group_by(\"lab_id\", \"behavior\", maintain_order=True)\ntotal_groups = len(list(groups))\nstart_time = time.perf_counter()\n\nfor idx, ((lab_id, behavior), group) in tqdm(enumerate(groups), total=total_groups):\n    if idx == 0:\n        tqdm.write(\n            f\"|{'LAB':^25}|{'BEHAVIOR':^15}|{'SAMPLES':^10}|{'POSITIVE':^10}|{'FEATURES':^10}|{'F1':^10}|{'ELAPSED TIME':^15}|\",\n            end=\"\\n\",\n        )\n\n    tqdm.write(f\"|{lab_id:^25}|{behavior:^15}|\", end=\"\")\n    index_list = []\n    feature_list = []\n    label_list = []\n\n    # Each data \n    for row in group.rows(named=True):\n        video_id = row[\"video_id\"]\n        agent = row[\"agent\"]\n\n        agent_mouse_id = int(re.search(r\"mouse(\\d+)\", agent).group(1))\n\n        data = pl.scan_parquet(WORKING_DIR / \"self_features\" / f\"{video_id}.parquet\").filter(\n            (pl.col(\"agent_mouse_id\") == agent_mouse_id)\n        )\n        index = data.select(INDEX_COLS).collect(engine=\"streaming\")\n        feature = data.select(pl.exclude(INDEX_COLS)).collect(engine=\"streaming\")\n\n        # read annotation\n        annotation_path = TRAIN_ANNOTATION_DIR / lab_id / f\"{video_id}.parquet\"\n        if annotation_path.exists():\n            annotation = (\n                pl.scan_parquet(annotation_path)\n                .filter((pl.col(\"action\") == behavior) & (pl.col(\"agent_id\") == agent_mouse_id))\n                .collect()\n            )\n        else:\n            annotation = pl.DataFrame(\n                schema={\n                    \"agent_id\": pl.Int8,\n                    \"target_id\": pl.Int8,\n                    \"action\": str,\n                    \"start_frame\": pl.Int16,\n                    \"stop_frame\": pl.Int16,\n                }\n            )\n\n        label_frames = set()\n        for annotation_row in annotation.rows(named=True):\n            label_frames.update(range(annotation_row[\"start_frame\"], annotation_row[\"stop_frame\"]))\n        label = index.select(pl.col(\"video_frame\").is_in(label_frames).cast(pl.Int8).alias(\"label\"))\n\n        if label.get_column(\"label\").sum() == 0:\n            continue\n\n        index_list.append(index)\n        feature_list.append(feature)\n        label_list.append(label.get_column(\"label\"))\n\n    if not index_list:\n        elapsed_time = datetime.timedelta(seconds=int(time.perf_counter() - start_time))\n        tqdm.write(f\"{0:>10,}|{0:>10,}|{0:>10,}|{'-':>10}|{str(elapsed_time):>15}|\", end=\"\\n\")\n        continue\n\n    indices = pl.concat(index_list, how=\"vertical\")\n    features = pl.concat(feature_list, how=\"vertical\")\n    labels = pl.concat(label_list, how=\"vertical\")\n\n    del index_list, feature_list, label_list\n    gc.collect()\n\n    tqdm.write(f\"{len(indices):>10,}|{labels.sum():>10,}|{len(features.columns):>10,}|\", end=\"\")\n\n    f1 = train_validate(lab_id, behavior, indices, features, labels)\n    tqdm.write(f\"{f1:>10.2f}|\", end=\"\")\n\n    elapsed_time = datetime.timedelta(seconds=int(time.perf_counter() - start_time))\n    tqdm.write(f\"{str(elapsed_time):>15}|\", end=\"\\n\")\n\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T01:35:26.840727Z","iopub.execute_input":"2025-11-22T01:35:26.841157Z","iopub.status.idle":"2025-11-22T02:03:26.501030Z","shell.execute_reply.started":"2025-11-22T01:35:26.841128Z","shell.execute_reply":"2025-11-22T02:03:26.499619Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/27 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10fb3b28f0a44b2da685d813a6eeb993"}},"metadata":{}},{"name":"stdout","text":"|           LAB           |   BEHAVIOR    | SAMPLES  | POSITIVE | FEATURES |    F1    | ELAPSED TIME  |\n|     AdaptableSnail      |     rear      |   660,348|    85,313|        66|      0.62|        0:01:40|\n|         CRIM13          |     rear      |   179,132|    12,042|        66|      0.38|        0:02:09|\n|         CRIM13          |   selfgroom   |   205,533|    14,472|        66|      0.35|        0:02:42|\n|      CalMS21_task1      | genitalgroom  |   102,445|     6,270|        66|      0.68|        0:03:08|\n|       ElegantMink       |     rear      |         0|         0|         0|         -|        0:03:09|\n|       ElegantMink       |   selfgroom   |         0|         0|         0|         -|        0:03:10|\n|       GroovyShrew       |     rear      |   899,280|    50,768|        66|      0.52|        0:04:58|\n|       GroovyShrew       |     rest      |   530,886|    87,573|        66|      0.66|        0:05:49|\n|       GroovyShrew       |   selfgroom   |   877,773|    22,893|        66|      0.34|        0:08:08|\n|       GroovyShrew       |     climb     |   295,943|     8,647|        66|      0.37|        0:08:46|\n|       GroovyShrew       |      dig      |   771,922|    31,267|        66|      0.40|        0:10:19|\n|       GroovyShrew       |      run      |   413,942|     1,732|        66|      0.17|        0:11:08|\n|   InvincibleJellyfish   |      dig      |   188,949|     6,768|        66|      0.29|        0:11:38|\n|   InvincibleJellyfish   |   selfgroom   |   308,326|     2,791|        66|      0.17|        0:12:25|\n|       LyricalHare       |    freeze     |   329,777|    31,660|        66|      0.53|        0:13:05|\n|       LyricalHare       |     rear      |   255,767|    18,953|        66|      0.36|        0:13:33|\n|     NiftyGoldfinch      |  biteobject   |   558,309|     2,326|        66|      0.03|        0:14:47|\n|     NiftyGoldfinch      |     climb     |   602,654|    51,687|        66|      0.56|        0:16:14|\n|     NiftyGoldfinch      |      dig      |   656,612|    40,735|        66|      0.50|        0:17:54|\n|     NiftyGoldfinch      | exploreobject |   558,859|     3,678|        66|      0.09|        0:19:08|\n|     NiftyGoldfinch      |     rear      |   602,308|    40,444|        66|      0.42|        0:20:28|\n|     NiftyGoldfinch      |   selfgroom   |   708,496|    34,621|        66|      0.44|        0:22:01|\n|     TranquilPanther     |     rear      | 1,234,586|    23,369|        66|      0.19|        0:24:53|\n|     TranquilPanther     |   selfgroom   | 1,021,199|     6,984|        66|      0.16|        0:27:16|\n|      UppityFerret       |    huddle     |   164,371|    24,148|        66|      0.63|        0:27:58|\n|      UppityFerret       |     rear      |         0|         0|         0|         -|        0:27:59|\n|      UppityFerret       |   selfgroom   |         0|         0|         0|         -|        0:27:59|\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"\"\"\"\npair features\n\"\"\"\ngroups = train_pair_behavior_dataframe.group_by(\"lab_id\", \"behavior\", maintain_order=True)\ntotal_groups = len(list(groups))\nstart_time = time.perf_counter()\n\nfor idx, ((lab_id, behavior), group) in tqdm(enumerate(groups), total=total_groups):\n    if idx == 0:\n        tqdm.write(\n            f\"|{'LAB':^25}|{'BEHAVIOR':^15}|{'SAMPLES':^10}|{'POSITIVE':^10}|{'FEATURES':^10}|{'F1':^10}|{'ELAPSED TIME':^15}|\",\n            end=\"\\n\",\n        )\n\n    tqdm.write(f\"|{lab_id:^25}|{behavior:^15}|\", end=\"\")\n    index_list = []\n    feature_list = []\n    label_list = []\n\n    for row in group.rows(named=True):\n        video_id = row[\"video_id\"]\n        agent = row[\"agent\"]\n        target = row[\"target\"]\n\n        agent_mouse_id = int(re.search(r\"mouse(\\d+)\", agent).group(1))\n        target_mouse_id = int(re.search(r\"mouse(\\d+)\", target).group(1))\n\n        data = pl.scan_parquet(WORKING_DIR / \"pair_features\" / f\"{video_id}.parquet\").filter(\n            (pl.col(\"agent_mouse_id\") == agent_mouse_id) & (pl.col(\"target_mouse_id\") == target_mouse_id)\n        )\n        index = data.select(INDEX_COLS).collect(engine=\"streaming\")\n        feature = data.select(pl.exclude(INDEX_COLS)).collect(engine=\"streaming\")\n\n        # read annotation\n        annotation_path = TRAIN_ANNOTATION_DIR / lab_id / f\"{video_id}.parquet\"\n        if annotation_path.exists():\n            annotation = (\n                pl.scan_parquet(annotation_path)\n                .filter(\n                    (pl.col(\"action\") == behavior)\n                    & (pl.col(\"agent_id\") == agent_mouse_id)\n                    & (pl.col(\"target_id\") == target_mouse_id)\n                )\n                .collect()\n            )\n        else:\n            annotation = pl.DataFrame(\n                schema={\n                    \"agent_id\": pl.Int8,\n                    \"target_id\": pl.Int8,\n                    \"action\": str,\n                    \"start_frame\": pl.Int16,\n                    \"stop_frame\": pl.Int16,\n                }\n            )\n\n        label_frames = set()\n        for annotation_row in annotation.rows(named=True):\n            label_frames.update(range(annotation_row[\"start_frame\"], annotation_row[\"stop_frame\"]))\n        label = index.select(pl.col(\"video_frame\").is_in(label_frames).cast(pl.Int8).alias(\"label\"))\n\n        if label.get_column(\"label\").sum() == 0:\n            continue\n\n        index_list.append(index)\n        feature_list.append(feature)\n        label_list.append(label.get_column(\"label\"))\n\n    if not index_list:\n        elapsed_time = datetime.timedelta(seconds=int(time.perf_counter() - start_time))\n        tqdm.write(f\"{0:>10,}|{0:>10,}|{0:>10,}|{'-':>10}|{str(elapsed_time):>15}|\", end=\"\\n\")\n        continue\n\n    indices = pl.concat(index_list, how=\"vertical\")\n    features = pl.concat(feature_list, how=\"vertical\")\n    labels = pl.concat(label_list, how=\"vertical\")\n\n    del index_list, feature_list, label_list\n    gc.collect()\n\n    tqdm.write(f\"{len(indices):>10,}|{labels.sum():>10,}|{len(features.columns):>10,}|\", end=\"\")\n\n    f1 = train_validate(lab_id, behavior, indices, features, labels)\n    tqdm.write(f\"{f1:>10.2f}|\", end=\"\")\n\n    elapsed_time = datetime.timedelta(seconds=int(time.perf_counter() - start_time))\n    tqdm.write(f\"{str(elapsed_time):>15}|\", end=\"\\n\")\n\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T02:03:26.502501Z","iopub.execute_input":"2025-11-22T02:03:26.503566Z","execution_failed":"2025-11-22T04:21:04.388Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/104 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81fdd036959d4e6aacf0cec4ce486ece"}},"metadata":{}},{"name":"stdout","text":"|           LAB           |   BEHAVIOR    | SAMPLES  | POSITIVE | FEATURES |    F1    | ELAPSED TIME  |\n|     AdaptableSnail      |   approach    | 1,524,536|     8,083|       143|      0.36|        0:05:00|\n|     AdaptableSnail      |    attack     | 2,436,568|    28,759|       143|      0.19|        0:11:49|\n|     AdaptableSnail      |     avoid     | 5,538,087|    22,923|       143|      0.17|        0:29:13|\n|     AdaptableSnail      |     chase     | 3,707,542|    14,739|       143|      0.15|        0:40:08|\n|     AdaptableSnail      |  chaseattack  | 1,217,344|     4,157|       143|      0.27|        0:44:01|\n|     AdaptableSnail      |    submit     |   424,181|     8,478|       143|      0.42|        0:45:43|\n|    BoisterousParrot     |   shepherd    | 9,504,414|    29,451|       143|      0.44|        1:13:57|\n|         CRIM13          |     mount     |   125,494|    10,340|       143|      0.68|        1:14:17|\n|         CRIM13          |     sniff     |   205,533|    30,218|       143|      0.68|        1:14:54|\n|  CalMS21_supplemental   |    attack     | 1,546,866|   179,193|       143|      0.82|        1:19:28|\n|  CalMS21_supplemental   |     sniff     | 5,179,395| 1,146,803|       143|","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"%%writefile robustify.py\n\ndef robustify(submission: pl.DataFrame, dataset: pl.DataFrame, train_test: str = \"train\"):\n    traintest_directory = INPUT_DIR / f\"{train_test}_tracking\"\n\n    old_submission = submission.clone()\n    submission = submission.filter(pl.col(\"start_frame\") < pl.col(\"stop_frame\"))\n    if len(submission) != len(old_submission):\n        print(\"ERROR: Dropped frames with start >= stop\")\n\n    old_submission = submission.clone()\n    group_list = []\n    for _, group in submission.group_by(\"video_id\", \"agent_id\", \"target_id\"):\n        group = group.sort(\"start_frame\")\n        mask = np.ones(len(group), dtype=bool)\n        last_stop_frame = 0\n        for i, row in enumerate(group.rows(named=True)):\n            if row[\"start_frame\"] < last_stop_frame:\n                mask[i] = False\n            else:\n                last_stop_frame = row[\"stop_frame\"]\n        group_list.append(group.filter(pl.Series(\"mask\", mask)))\n\n    submission = pl.concat(group_list)\n\n    if len(submission) != len(old_submission):\n        print(\"ERROR: Dropped duplicate frames\")\n\n    s_list = []\n    for row in dataset.rows(named=True):\n        lab_id = row[\"lab_id\"]\n        video_id = row[\"video_id\"]\n        if row[\"behaviors_labeled\"] is None:\n            continue\n\n        if video_id in submission.get_column(\"video_id\").to_list():\n            continue\n\n        if isinstance(row[\"behaviors_labeled\"], str):\n            continue\n\n        print(f\"Video {video_id} has no predictions.\")\n\n        path = traintest_directory / f\"/{lab_id}/{video_id}.parquet\"\n        vid = pd.read_parquet(path)\n\n        vid_behaviors = json.loads(row[\"behaviors_labeled\"])\n        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n        vid_behaviors = [b.split(\",\") for b in vid_behaviors]\n        vid_behaviors = pd.DataFrame(vid_behaviors, columns=[\"agent\", \"target\", \"action\"])\n\n        start_frame = vid.video_frame.min()\n        stop_frame = vid.video_frame.max() + 1\n\n        for (agent, target), actions in vid_behaviors.groupby([\"agent\", \"target\"]):\n            batch_length = int(np.ceil((stop_frame - start_frame) / len(actions)))\n            for i, action_row in enumerate(actions.itertuples(index=False)):\n                batch_start = start_frame + i * batch_length\n                batch_stop = min(batch_start + batch_length, stop_frame)\n                s_list.append((video_id, agent, target, action_row[\"action\"], batch_start, batch_stop))\n\n    if len(s_list) > 0:\n        submission = pd.concat(\n            [\n                submission,\n                pd.DataFrame(s_list, columns=[\"video_id\", \"agent_id\", \"target_id\", \"action\", \"start_frame\", \"stop_frame\"]),\n            ]\n        )\n        print(\"ERROR: Filled empty videos\")\n\n    return submission","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-22T04:21:04.389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"group_oof_predictions = []\ngroups = train_behavior_dataframe.group_by(\"lab_id\", \"video_id\", \"agent\", \"target\", maintain_order=True)\n\nfor (lab_id, video_id, agent, target), group in tqdm(groups, total=len(list(groups))):\n    agent_mouse_id = int(re.search(r\"mouse(\\d+)\", agent).group(1))\n    target_mouse_id = -1 if target == \"self\" else int(re.search(r\"mouse(\\d+)\", target).group(1))\n\n    prediction_dataframe_list = []\n\n    for row in group.rows(named=True):\n        behavior = row[\"behavior\"]\n\n        oof_path = WORKING_DIR / \"results\" / lab_id / behavior / \"oof_predictions.parquet\"\n        if not oof_path.exists():\n            continue\n\n        prediction = (\n            pl.scan_parquet(oof_path)\n            .filter(\n                (pl.col(\"video_id\") == video_id)\n                & (pl.col(\"agent_mouse_id\") == agent_mouse_id)\n                & (pl.col(\"target_mouse_id\") == target_mouse_id)\n            )\n            .select(*INDEX_COLS, (pl.col(\"prediction\") * pl.col(\"predicted_label\")).alias(behavior))\n            .collect()\n        )\n\n        if len(prediction) == 0:\n            continue\n\n        prediction_dataframe_list.append(prediction)\n\n    if not prediction_dataframe_list:\n        continue\n\n    prediction_dataframe = pl.concat(prediction_dataframe_list, how=\"align\")\n\n    cols = prediction_dataframe.select(pl.exclude(INDEX_COLS)).columns\n    prediction_labels_dataframe = prediction_dataframe.with_columns(\n        pl.struct(pl.exclude(INDEX_COLS))\n        .map_elements(\n            lambda row: \"none\" if sum(row.values()) == 0 else (cols[np.argmax(list(row.values()))]),\n            return_dtype=pl.String,\n        )\n        .alias(\"prediction\")\n    ).select(INDEX_COLS + [\"prediction\"])\n\n    group_oof_prediction = (\n        prediction_labels_dataframe.filter((pl.col(\"prediction\") != pl.col(\"prediction\").shift(1)))\n        .with_columns(pl.col(\"video_frame\").shift(-1).alias(\"stop_frame\"))\n        .filter(pl.col(\"prediction\") != \"none\")\n        .select(\n            pl.col(\"video_id\"),\n            (\"mouse\" + pl.col(\"agent_mouse_id\").cast(str)).alias(\"agent_id\"),\n            pl.when(pl.col(\"target_mouse_id\") == -1)\n            .then(pl.lit(\"self\"))\n            .otherwise(\"mouse\" + pl.col(\"target_mouse_id\").cast(str))\n            .alias(\"target_id\"),\n            pl.col(\"prediction\").alias(\"action\"),\n            pl.col(\"video_frame\").alias(\"start_frame\"),\n            pl.col(\"stop_frame\"),\n        )\n    )\n\n    group_oof_predictions.append(group_oof_prediction)\n\n%run -i robustify.py\n\noof_predictions = pl.concat(group_oof_predictions, how=\"vertical\")\noof_predictions = robustify(oof_predictions, train_dataframe, train_test=\"train\")\noof_predictions.with_row_index(\"row_id\").write_csv(WORKING_DIR / \"oof_predictions.csv\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-22T04:21:04.389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_validation_metrics(submission, verbose=True):\n    \"\"\"Compute and display validation metrics for single vs pair behaviors.\"\"\"\n    # solution_df\n    dataset = pl.read_csv(INPUT_DIR / \"train.csv\").to_pandas()\n\n    solution = []\n    for _, row in dataset.iterrows():\n        lab_id = row[\"lab_id\"]\n        if lab_id.startswith(\"MABe22\"):\n            continue\n\n        video_id = row[\"video_id\"]\n        path = TRAIN_ANNOTATION_DIR / lab_id / f\"{video_id}.parquet\"\n        try:\n            annot = pd.read_parquet(path)\n        except FileNotFoundError:\n            continue\n\n        annot[\"lab_id\"] = lab_id\n        annot[\"video_id\"] = video_id\n        annot[\"behaviors_labeled\"] = row[\"behaviors_labeled\"]\n        annot[\"target_id\"] = np.where(\n            annot.target_id != annot.agent_id, annot[\"target_id\"].apply(lambda s: f\"mouse{s}\"), \"self\"\n        )\n        annot[\"agent_id\"] = annot[\"agent_id\"].apply(lambda s: f\"mouse{s}\")\n        solution.append(annot)\n\n    solution = pd.concat(solution)\n\n    try:\n        # Separate single and pair behaviors\n        submission_single = submission[submission[\"target_id\"] == \"self\"].copy()\n        submission_pair = submission[submission[\"target_id\"] != \"self\"].copy()\n\n        # Filter solution to match submission videos\n        solution_videos = set(submission[\"video_id\"].unique())\n        solution = solution[solution[\"video_id\"].isin(solution_videos)]\n\n        if len(solution) == 0:\n            return\n\n        # Compute overall F1 score\n        overall_f1 = score(solution, submission, \"row_id\", beta=1.0)\n        print(f\"\\n{'=' * 60}\")\n        print(\"PERFORMANCE METRICS\")\n        print(f\"{'=' * 60}\")\n        print(f\"Overall F1 Score: {overall_f1:.4f}\")\n        print(f\"Total predictions: {len(submission)}\")\n        print(f\"  - Single behaviors: {len(submission_single)}\")\n        print(f\"  - Pair behaviors: {len(submission_pair)}\")\n\n        # Compute per-action F1 scores using existing scoring function\n        solution_pl = pl.DataFrame(solution)\n        submission_pl = pl.DataFrame(submission)\n\n        # Add label_key and prediction_key\n        solution_pl = solution_pl.with_columns(\n            pl.concat_str(\n                [\n                    pl.col(\"video_id\").cast(pl.Utf8),\n                    pl.col(\"agent_id\").cast(pl.Utf8),\n                    pl.col(\"target_id\").cast(pl.Utf8),\n                    pl.col(\"action\"),\n                ],\n                separator=\"_\",\n            ).alias(\"label_key\"),\n        )\n        submission_pl = submission_pl.with_columns(\n            pl.concat_str(\n                [\n                    pl.col(\"video_id\").cast(pl.Utf8),\n                    pl.col(\"agent_id\").cast(pl.Utf8),\n                    pl.col(\"target_id\").cast(pl.Utf8),\n                    pl.col(\"action\"),\n                ],\n                separator=\"_\",\n            ).alias(\"prediction_key\"),\n        )\n\n        # Group by action and compute metrics\n        action_stats = defaultdict(lambda: {\"single\": {\"count\": 0, \"f1\": 0.0}, \"pair\": {\"count\": 0, \"f1\": 0.0}})\n\n        for lab in solution_pl[\"lab_id\"].unique():\n            lab_solution = solution_pl.filter(pl.col(\"lab_id\") == lab).clone()\n            lab_videos = set(lab_solution[\"video_id\"].unique())\n            lab_submission = submission_pl.filter(pl.col(\"video_id\").is_in(lab_videos)).clone()\n\n            # Compute per-action F1 using same logic as single_lab_f1\n            label_frames = defaultdict(set)\n            prediction_frames = defaultdict(set)\n\n            for row in lab_solution.to_dicts():\n                label_frames[row[\"label_key\"]].update(range(row[\"start_frame\"], row[\"stop_frame\"]))\n\n            for row in lab_submission.to_dicts():\n                key = row[\"prediction_key\"]\n                prediction_frames[key].update(range(row[\"start_frame\"], row[\"stop_frame\"]))\n\n            for key in set(list(label_frames.keys()) + list(prediction_frames.keys())):\n                action = key.split(\"_\")[-1]\n                mode = \"single\" if \"self\" in key else \"pair\"\n\n                pred_frames = prediction_frames.get(key, set())\n                label_frames_set = label_frames.get(key, set())\n\n                tp = len(pred_frames & label_frames_set)\n                fn = len(label_frames_set - pred_frames)\n                fp = len(pred_frames - label_frames_set)\n\n                if tp + fn + fp > 0:\n                    f1 = (1 + 1**2) * tp / ((1 + 1**2) * tp + 1**2 * fn + fp)\n                    action_stats[action][mode][\"count\"] += 1\n                    action_stats[action][mode][\"f1\"] += f1\n\n        # Print per-action summary\n        print(\"\\nPer-Action Performance Summary:\")\n        print(f\"{'-' * 60}\")\n        print(f\"{'Action':<20} {'Mode':<10} {'Count':<10} {'Avg F1':<10}\")\n        print(f\"{'-' * 60}\")\n\n        for action in sorted(action_stats.keys()):\n            for mode in [\"single\", \"pair\"]:\n                stats = action_stats[action][mode]\n                if stats[\"count\"] > 0:\n                    avg_f1 = stats[\"f1\"] / stats[\"count\"]\n                    print(f\"{action:<20} {mode:<10} {stats['count']:<10} {avg_f1:<10.4f}\")\n\n        # Summary by mode\n        single_actions = [a for a in action_stats.keys() if action_stats[a][\"single\"][\"count\"] > 0]\n        pair_actions = [a for a in action_stats.keys() if action_stats[a][\"pair\"][\"count\"] > 0]\n\n        if single_actions:\n            single_avg_f1 = np.mean(\n                [\n                    action_stats[a][\"single\"][\"f1\"] / action_stats[a][\"single\"][\"count\"]\n                    for a in single_actions\n                    if action_stats[a][\"single\"][\"count\"] > 0\n                ]\n            )\n            print(f\"\\nSingle behaviors: {len(single_actions)} actions, Avg F1: {single_avg_f1:.4f}\")\n\n        if pair_actions:\n            pair_avg_f1 = np.mean(\n                [\n                    action_stats[a][\"pair\"][\"f1\"] / action_stats[a][\"pair\"][\"count\"]\n                    for a in pair_actions\n                    if action_stats[a][\"pair\"][\"count\"] > 0\n                ]\n            )\n            print(f\"Pair behaviors: {len(pair_actions)} actions, Avg F1: {pair_avg_f1:.4f}\")\n\n        print(f\"{'=' * 60}\\n\")\n\n    except Exception as e:\n        if verbose:\n            error_msg = str(e)\n            if len(error_msg) > 200:\n                error_msg = error_msg[:200] + \"...\"\n            print(f\"\\nWarning: Could not compute validation metrics: {error_msg}\")\n            if verbose:\n                print(f\"Traceback: {traceback.format_exc()[:300]}\")\n\ncompute_validation_metrics(submission=pd.read_csv(WORKING_DIR / \"oof_predictions.csv\"))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-22T04:21:04.389Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"# read data\ntest_dataframe = pl.read_csv(INPUT_DIR / \"test.csv\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-22T04:21:04.389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# preprocess behavior labels\ntest_behavior_dataframe = (\n    test_dataframe.filter(pl.col(\"behaviors_labeled\").is_not_null())\n    .select(\n        pl.col(\"lab_id\"),\n        pl.col(\"video_id\"),\n        pl.col(\"behaviors_labeled\").map_elements(eval, return_dtype=pl.List(pl.Utf8)).alias(\"behaviors_labeled_list\"),\n    )\n    .explode(\"behaviors_labeled_list\")\n    .rename({\"behaviors_labeled_list\": \"behaviors_labeled_element\"})\n    .select(\n        pl.col(\"lab_id\"),\n        pl.col(\"video_id\"),\n        pl.col(\"behaviors_labeled_element\").str.split(\",\").list[0].str.replace_all(\"'\", \"\").alias(\"agent\"),\n        pl.col(\"behaviors_labeled_element\").str.split(\",\").list[1].str.replace_all(\"'\", \"\").alias(\"target\"),\n        pl.col(\"behaviors_labeled_element\").str.split(\",\").list[2].str.replace_all(\"'\", \"\").alias(\"behavior\"),\n    )\n)\n\ntest_self_behavior_dataframe = test_behavior_dataframe.filter(pl.col(\"behavior\").is_in(SELF_BEHAVIORS))\ntest_pair_behavior_dataframe = test_behavior_dataframe.filter(pl.col(\"behavior\").is_in(PAIR_BEHAVIORS))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-22T04:21:04.389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"(WORKING_DIR / \"self_features\").mkdir(exist_ok=True, parents=True)\n(WORKING_DIR / \"pair_features\").mkdir(exist_ok=True, parents=True)\n\nrows = test_dataframe.rows(named=True)\n\nfor row in tqdm(rows, total=len(rows)):\n    lab_id = row[\"lab_id\"]\n    video_id = row[\"video_id\"]\n\n    tracking_path = TEST_TRACKING_DIR / f\"{lab_id}/{video_id}.parquet\"\n    tracking = pl.read_parquet(tracking_path)\n\n    self_features = make_self_features(metadata=row, tracking=tracking)\n    pair_features = make_pair_features(metadata=row, tracking=tracking)\n\n    self_features.write_parquet(WORKING_DIR / \"self_features\" / f\"{video_id}.parquet\")\n    pair_features.write_parquet(WORKING_DIR / \"pair_features\" / f\"{video_id}.parquet\")\n\n    del self_features, pair_features\n    gc.collect()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-22T04:21:04.390Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"group_submissions = []\ngroups = list(test_behavior_dataframe.group_by(\"lab_id\", \"video_id\", \"agent\", \"target\", maintain_order=True))\n\nfor (lab_id, video_id, agent, target), group in tqdm(groups, total=len(list(groups))):\n    agent_mouse_id = int(re.search(r\"mouse(\\d+)\", agent).group(1))\n    target_mouse_id = -1 if target == \"self\" else int(re.search(r\"mouse(\\d+)\", target).group(1))\n\n    if target == \"self\":\n        index = (\n            pl.scan_parquet(WORKING_DIR / \"self_features\" / f\"{video_id}.parquet\")\n            .filter((pl.col(\"agent_mouse_id\") == agent_mouse_id))\n            .select(INDEX_COLS)\n            .collect()\n        )\n        feature = (\n            pl.scan_parquet(WORKING_DIR / \"self_features\" / f\"{video_id}.parquet\")\n            .filter((pl.col(\"agent_mouse_id\") == agent_mouse_id))\n            .select(pl.exclude(INDEX_COLS))\n            .collect()\n        )\n    else:\n        index = (\n            pl.scan_parquet(WORKING_DIR / \"pair_features\" / f\"{video_id}.parquet\")\n            .filter((pl.col(\"agent_mouse_id\") == agent_mouse_id) & (pl.col(\"target_mouse_id\") == target_mouse_id))\n            .select(INDEX_COLS)\n            .collect()\n        )\n        feature = (\n            pl.scan_parquet(WORKING_DIR / \"pair_features\" / f\"{video_id}.parquet\")\n            .filter((pl.col(\"agent_mouse_id\") == agent_mouse_id) & (pl.col(\"target_mouse_id\") == target_mouse_id))\n            .select(pl.exclude(INDEX_COLS))\n            .collect()\n        )\n\n    prediction_dataframe = index.clone()\n\n    for row in group.rows(named=True):\n        behavior = row[\"behavior\"]\n\n        predictions = []\n        prediction_labels = []\n\n        fold_dirs = list((WORKING_DIR / \"results\" / lab_id / behavior).glob(\"fold_*\"))\n        if not fold_dirs:\n            continue\n\n        for fold_dir in fold_dirs:\n            with open(fold_dir / \"threshold.txt\", \"r\") as f:\n                threshold = float(f.read().strip())\n            model = xgb.Booster(model_file=fold_dir / \"model.json\")\n            dtest = xgb.DMatrix(feature, feature_names=feature.columns)\n            fold_predictions = model.predict(dtest)\n            predictions.append(fold_predictions)\n            prediction_labels.append((fold_predictions >= threshold).astype(np.int8))\n\n        prediction_dataframe = prediction_dataframe.with_columns(\n            *[\n                pl.Series(name=f\"{behavior}_{fold}\", values=predictions[fold] * prediction_labels[fold], dtype=pl.Float32)\n                for fold in range(len(fold_dirs))\n            ]\n        )\n\n    cols = prediction_dataframe.select(pl.exclude(INDEX_COLS)).columns\n    if not cols:\n        tqdm.write(f\"Warning: No predictions found for {lab_id}, {video_id}, {agent}, {target}\")\n        continue\n\n    prediction_labels_dataframe = prediction_dataframe.with_columns(\n        pl.struct(pl.col(cols))\n        .map_elements(\n            lambda row: \"none\" if sum(row.values()) == 0 else (cols[np.argmax(list(row.values()))]).split(\"_\")[0],\n            return_dtype=pl.String,\n        )\n        .alias(\"prediction\")\n    ).select(INDEX_COLS + [\"prediction\"])\n\n    group_submission = (\n        prediction_labels_dataframe.filter((pl.col(\"prediction\") != pl.col(\"prediction\").shift(1)))\n        .with_columns(pl.col(\"video_frame\").shift(-1).alias(\"stop_frame\"))\n        .filter(pl.col(\"prediction\") != \"none\")\n        .select(\n            pl.col(\"video_id\"),\n            (\"mouse\" + pl.col(\"agent_mouse_id\").cast(str)).alias(\"agent_id\"),\n            pl.when(pl.col(\"target_mouse_id\") == -1)\n            .then(pl.lit(\"self\"))\n            .otherwise(\"mouse\" + pl.col(\"target_mouse_id\").cast(str))\n            .alias(\"target_id\"),\n            pl.col(\"prediction\").alias(\"action\"),\n            pl.col(\"video_frame\").alias(\"start_frame\"),\n            pl.col(\"stop_frame\"),\n        )\n    )\n\n    group_submissions.append(group_submission)\n\nsubmission = pl.concat(group_submissions, how=\"vertical\").sort(\n    \"video_id\",\n    \"agent_id\",\n    \"target_id\",\n    \"action\",\n    \"start_frame\",\n    \"stop_frame\",\n)\nsubmission = robustify(submission, test_dataframe, train_test=\"test\")\nsubmission.with_row_index(\"row_id\").write_csv(WORKING_DIR / \"submission.csv\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-22T04:21:04.390Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!head submission.csv","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-22T04:21:04.390Z"}},"outputs":[],"execution_count":null}]}