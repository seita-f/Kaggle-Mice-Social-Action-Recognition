{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":59156,"databundleVersionId":13874099,"sourceType":"competition"},{"sourceId":262477103,"sourceType":"kernelVersion"},{"sourceId":279806245,"sourceType":"kernelVersion"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q --no-index --find-links=/kaggle/input/mabe-package xgboost==3.1.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:09:36.557435Z","iopub.execute_input":"2025-11-24T14:09:36.558037Z","iopub.status.idle":"2025-11-24T14:09:39.796686Z","shell.execute_reply.started":"2025-11-24T14:09:36.558011Z","shell.execute_reply":"2025-11-24T14:09:39.795621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import datetime\nimport gc\nimport itertools\nimport json\nimport re\nimport sys\nimport time\nimport traceback\nfrom collections import defaultdict\nfrom pathlib import Path\n\nimport joblib\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport xgboost as xgb\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom tqdm.auto import tqdm\n\nsys.path.append(\"/kaggle/usr/lib/mabe-f-beta\")\nfrom metric import score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:09:39.798162Z","iopub.execute_input":"2025-11-24T14:09:39.798394Z","iopub.status.idle":"2025-11-24T14:09:39.804068Z","shell.execute_reply.started":"2025-11-24T14:09:39.798373Z","shell.execute_reply":"2025-11-24T14:09:39.803410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# const\nINPUT_DIR = Path(\"/kaggle/input/MABe-mouse-behavior-detection\")\nTRAIN_TRACKING_DIR = INPUT_DIR / \"train_tracking\"\nTRAIN_ANNOTATION_DIR = INPUT_DIR / \"train_annotation\"\nTEST_TRACKING_DIR = INPUT_DIR / \"test_tracking\"\n\nWORKING_DIR = Path(\"/kaggle/working\")\n\nINDEX_COLS = [\n    \"video_id\",\n    \"agent_mouse_id\",\n    \"target_mouse_id\",\n    \"video_frame\",\n]\n\nBODY_PARTS = [\n    \"ear_left\",\n    \"ear_right\",\n    \"nose\",\n    \"neck\",\n    \"body_center\",\n    \"lateral_left\",\n    \"lateral_right\",\n    \"hip_left\",\n    \"hip_right\",\n    \"tail_base\",\n    \"tail_tip\",\n]\n\nSELF_BEHAVIORS = [\n    \"biteobject\",\n    \"climb\",\n    \"dig\",\n    \"exploreobject\",\n    \"freeze\",\n    \"genitalgroom\",\n    \"huddle\",\n    \"rear\",\n    \"rest\",\n    \"run\",\n    \"selfgroom\",\n]\n\nPAIR_BEHAVIORS = [\n    \"allogroom\",\n    \"approach\",\n    \"attack\",\n    \"attemptmount\",\n    \"avoid\",\n    \"chase\",\n    \"chaseattack\",\n    \"defend\",\n    \"disengage\",\n    \"dominance\",\n    \"dominancegroom\",\n    \"dominancemount\",\n    \"ejaculate\",\n    \"escape\",\n    \"flinch\",\n    \"follow\",\n    \"intromit\",\n    \"mount\",\n    \"reciprocalsniff\",\n    \"shepherd\",\n    \"sniff\",\n    \"sniffbody\",\n    \"sniffface\",\n    \"sniffgenital\",\n    \"submit\",\n    \"tussle\",\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:09:39.805102Z","iopub.execute_input":"2025-11-24T14:09:39.805284Z","iopub.status.idle":"2025-11-24T14:09:39.819781Z","shell.execute_reply.started":"2025-11-24T14:09:39.805271Z","shell.execute_reply":"2025-11-24T14:09:39.819109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# read data\ntrain_dataframe = pl.read_csv(INPUT_DIR / \"train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:09:39.821253Z","iopub.execute_input":"2025-11-24T14:09:39.821520Z","iopub.status.idle":"2025-11-24T14:09:39.848266Z","shell.execute_reply.started":"2025-11-24T14:09:39.821496Z","shell.execute_reply":"2025-11-24T14:09:39.847736Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Processing","metadata":{}},{"cell_type":"markdown","source":"## Pre-preparation","metadata":{}},{"cell_type":"code","source":"# preprocess behavior labels\ntrain_behavior_dataframe = (\n    train_dataframe.filter(pl.col(\"behaviors_labeled\").is_not_null())\n    .select(\n        pl.col(\"lab_id\"),\n        pl.col(\"video_id\"),\n        pl.col(\"behaviors_labeled\").map_elements(eval, return_dtype=pl.List(pl.Utf8)).alias(\"behaviors_labeled_list\"),\n    )\n    .explode(\"behaviors_labeled_list\")\n    .rename({\"behaviors_labeled_list\": \"behaviors_labeled_element\"})\n    .select(\n        pl.col(\"lab_id\"),\n        pl.col(\"video_id\"),\n        pl.col(\"behaviors_labeled_element\").str.split(\",\").list[0].str.replace_all(\"'\", \"\").alias(\"agent\"),\n        pl.col(\"behaviors_labeled_element\").str.split(\",\").list[1].str.replace_all(\"'\", \"\").alias(\"target\"),\n        pl.col(\"behaviors_labeled_element\").str.split(\",\").list[2].str.replace_all(\"'\", \"\").alias(\"behavior\"),\n    )\n)\n\ntrain_self_behavior_dataframe = train_behavior_dataframe.filter(pl.col(\"behavior\").is_in(SELF_BEHAVIORS))\ntrain_pair_behavior_dataframe = train_behavior_dataframe.filter(pl.col(\"behavior\").is_in(PAIR_BEHAVIORS))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:09:39.848859Z","iopub.execute_input":"2025-11-24T14:09:39.849049Z","iopub.status.idle":"2025-11-24T14:09:39.900672Z","shell.execute_reply.started":"2025-11-24T14:09:39.849028Z","shell.execute_reply":"2025-11-24T14:09:39.900123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_self_behavior_dataframe.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:09:39.901416Z","iopub.execute_input":"2025-11-24T14:09:39.901657Z","iopub.status.idle":"2025-11-24T14:09:39.907728Z","shell.execute_reply.started":"2025-11-24T14:09:39.901632Z","shell.execute_reply":"2025-11-24T14:09:39.907105Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_pair_behavior_dataframe.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:09:39.908476Z","iopub.execute_input":"2025-11-24T14:09:39.908713Z","iopub.status.idle":"2025-11-24T14:09:39.919385Z","shell.execute_reply.started":"2025-11-24T14:09:39.908697Z","shell.execute_reply":"2025-11-24T14:09:39.918749Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"\"\"\"\nRemove Outliers\n\"\"\"\ndef compute_framewise_median(df: pl.DataFrame):\n\n    x_cols = [c for c in df.columns if c.endswith(\"_x\")]\n    y_cols = [c for c in df.columns if c.endswith(\"_y\")]\n\n    if len(x_cols) == 0 or len(y_cols) == 0:\n        return df.with_columns([\n            pl.lit(None).alias(\"median_x\"),\n            pl.lit(None).alias(\"median_y\"),\n        ])\n        \n    df = df.with_columns([\n        pl.concat_list(x_cols).list.median().alias(\"median_x\"),\n        pl.concat_list(y_cols).list.median().alias(\"median_y\"),\n    ])\n\n    return df\n\ndef add_distance_columns(df: pl.DataFrame):\n    for col in df.columns:\n        if col.endswith(\"_x\"):\n            bp = col[:-2]  # bodypart name\n\n            df = df.with_columns(\n                (\n                    (pl.col(f\"{bp}_x\").cast(pl.Float32) - pl.col(\"median_x\").cast(pl.Float32)) ** 2 +\n                    (pl.col(f\"{bp}_y\").cast(pl.Float32) - pl.col(\"median_y\").cast(pl.Float32)) ** 2\n                ).sqrt().alias(f\"{bp}_dist\")\n            )\n    return df\n\ndef apply_outlier_nan(df: pl.DataFrame, dist_thresh=17.0):\n    for col in df.columns:\n        if col.endswith(\"_dist\"):\n            bp = col[:-5]\n\n            df = df.with_columns([\n                pl.when(pl.col(col) > dist_thresh)\n                  .then(None)\n                  .otherwise(pl.col(f\"{bp}_x\"))\n                  .alias(f\"{bp}_x\"),\n                pl.when(pl.col(col) > dist_thresh)\n                  .then(None)\n                  .otherwise(pl.col(f\"{bp}_y\"))\n                  .alias(f\"{bp}_y\")\n            ])\n    return df\n\n\ndef clean_outliers_polars(df: pl.DataFrame, dist_thresh=17.0):\n    df = compute_framewise_median(df)\n    df = add_distance_columns(df)\n    df = apply_outlier_nan(df, dist_thresh)\n\n    drop_cols = [c for c in df.columns if c.endswith(\"_dist\") or c in [\"median_x\", \"median_y\"]]\n    df = df.drop(drop_cols)\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:09:39.920013Z","iopub.execute_input":"2025-11-24T14:09:39.920179Z","iopub.status.idle":"2025-11-24T14:09:39.934023Z","shell.execute_reply.started":"2025-11-24T14:09:39.920166Z","shell.execute_reply":"2025-11-24T14:09:39.933278Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile self_features.py\n\ndef make_self_features(\n    metadata: dict,\n    tracking: pl.DataFrame,\n) -> pl.DataFrame:\n    def body_parts_distance(body_part_1, body_part_2):\n        # The distance between each agent bodypart\n        assert body_part_1 in BODY_PARTS\n        assert body_part_2 in BODY_PARTS\n        return (\n            (pl.col(f\"agent_x_{body_part_1}\") - pl.col(f\"agent_x_{body_part_2}\")).pow(2)\n            + (pl.col(f\"agent_y_{body_part_1}\") - pl.col(f\"agent_y_{body_part_2}\")).pow(2)\n        ).sqrt() / metadata[\"pix_per_cm_approx\"]\n\n    def body_part_speed(body_part, period_ms):\n        # Approximate velocity of the bodypart (cm/s)\n        assert body_part in BODY_PARTS\n        window_frames = max(1, int(round(period_ms * metadata[\"frames_per_second\"] / 1000.0)))\n        # return (\n        #     ((pl.col(f\"agent_x_{body_part}\").diff()).pow(2) + (pl.col(f\"agent_y_{body_part}\").diff()).pow(2)).sqrt()\n        #     / metadata[\"pix_per_cm_approx\"]\n        #     * metadata[\"frames_per_second\"]\n        # ).rolling_mean(window_size=window_frames, center=True)\n        x = pl.col(f\"agent_x_{body_part}\").cast(pl.Float32)\n        y = pl.col(f\"agent_y_{body_part}\").cast(pl.Float32)\n    \n        return (\n            ((x.diff()).pow(2) + (y.diff()).pow(2)).sqrt()\n            / metadata[\"pix_per_cm_approx\"]\n            * metadata[\"frames_per_second\"]\n        ).rolling_mean(window_size=window_frames, center=True)\n    \n    def elongation():\n        d1 = body_parts_distance(\"nose\", \"tail_base\")\n        d2 = body_parts_distance(\"ear_left\", \"ear_right\")\n        return d1 / (d2 + 1e-06)\n\n    def body_angle():\n        v1x = pl.col(\"agent_x_nose\") - pl.col(\"agent_x_body_center\")\n        v1y = pl.col(\"agent_y_nose\") - pl.col(\"agent_y_body_center\")\n        v2x = pl.col(\"agent_x_tail_base\") - pl.col(\"agent_x_body_center\")\n        v2y = pl.col(\"agent_y_tail_base\") - pl.col(\"agent_y_body_center\")\n        return (v1x * v2x + v1y * v2y) / ((v1x.pow(2) + v1y.pow(2)).sqrt() * (v2x.pow(2) + v2y.pow(2)).sqrt() + 1e-06)\n\n    # number of detected mice\n    n_mice = (\n        (metadata[\"mouse1_strain\"] is not None)\n        + (metadata[\"mouse2_strain\"] is not None)\n        + (metadata[\"mouse3_strain\"] is not None)\n        + (metadata[\"mouse4_strain\"] is not None)\n    )\n    \n    start_frame = tracking.select(pl.col(\"video_frame\").min()).item()\n    end_frame = tracking.select(pl.col(\"video_frame\").max()).item()\n\n    result = []\n\n    pivot = tracking.pivot(\n        on=[\"bodypart\"],\n        index=[\"video_frame\", \"mouse_id\"],\n        values=[\"x\", \"y\"],\n    ).sort([\"mouse_id\", \"video_frame\"])\n    # pivot_trackings = {mouse_id: pivot.filter(pl.col(\"mouse_id\") == mouse_id) for mouse_id in range(1, n_mice + 1)}\n\n    pivot_trackings = {}\n\n    for mouse_id in range(1, n_mice + 1):\n        df_mouse = pivot.filter(pl.col(\"mouse_id\") == mouse_id)\n        df_mouse_clean = clean_outliers_polars(df_mouse, dist_thresh=17.0)\n        pivot_trackings[mouse_id] = df_mouse_clean\n\n    for agent_mouse_id in range(1, n_mice + 1):\n        result_element = pl.DataFrame(\n            {\n                \"video_id\": metadata[\"video_id\"],\n                \"agent_mouse_id\": agent_mouse_id,\n                \"target_mouse_id\": -1,\n                \"video_frame\": pl.arange(start_frame, end_frame + 1, eager=True),\n            },\n            schema={\n                \"video_id\": pl.Int32,\n                \"agent_mouse_id\": pl.Int8,\n                \"target_mouse_id\": pl.Int8,\n                \"video_frame\": pl.Int32,\n            },\n        )\n\n        pivot = pivot_trackings[agent_mouse_id].select(\n            pl.col(\"video_frame\"),\n            pl.from_epoch(\n                pl.col(\"video_frame\").truediv(metadata[\"frames_per_second\"]).mul(1_000_000),\n                time_unit=\"us\",\n            ).alias(\"timestamp\"),\n            pl.exclude(\"video_frame\").name.prefix(\"agent_\"),\n        )\n        columns = pivot.columns\n        pivot = pivot.with_columns(\n            *[pl.lit(None).cast(pl.Float32).alias(f\"agent_x_{bp}\") for bp in BODY_PARTS if f\"agent_x_{bp}\" not in columns],\n            *[pl.lit(None).cast(pl.Float32).alias(f\"agent_y_{bp}\") for bp in BODY_PARTS if f\"agent_y_{bp}\" not in columns],\n        )\n\n        features = pivot.with_columns(\n            pl.lit(agent_mouse_id).alias(\"agent_mouse_id\"),\n            pl.lit(-1).alias(\"target_mouse_id\"),\n        ).select(\n            pl.col(\"video_frame\"),\n            pl.col(\"agent_mouse_id\"),\n            pl.col(\"target_mouse_id\"),\n            *[\n                body_parts_distance(body_part_1, body_part_2).alias(f\"aa__{body_part_1}__{body_part_2}__distance\")\n                for body_part_1, body_part_2 in itertools.combinations(BODY_PARTS, 2)\n            ],\n            *[\n                body_part_speed(body_part, period_ms).alias(f\"agent__{body_part}__speed_{period_ms}ms\")\n                for body_part, period_ms in itertools.product([\"ear_left\", \"ear_right\", \"tail_base\"], [500, 1000, 2000])\n            ],\n            elongation().alias(\"agent__elongation\"),\n            body_angle().alias(\"agent__body_angle\"),\n        )\n\n        result_element = result_element.join(\n            features,\n            on=[\"video_frame\", \"agent_mouse_id\", \"target_mouse_id\"],\n            how=\"left\",\n        )\n        result.append(result_element)\n\n    return pl.concat(result, how=\"vertical\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:09:39.934721Z","iopub.execute_input":"2025-11-24T14:09:39.934967Z","iopub.status.idle":"2025-11-24T14:09:39.951818Z","shell.execute_reply.started":"2025-11-24T14:09:39.934945Z","shell.execute_reply":"2025-11-24T14:09:39.951240Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile pair_features.py\n\ndef make_pair_features(\n    metadata: dict,\n    tracking: pl.DataFrame,\n) -> pl.DataFrame:\n    def body_parts_distance(agent_or_target_1, body_part_1, agent_or_target_2, body_part_2):\n        # Distance of each bodypart between agent-target\n        assert agent_or_target_1 == \"agent\" or agent_or_target_1 == \"target\"\n        assert agent_or_target_2 == \"agent\" or agent_or_target_2 == \"target\"\n        assert body_part_1 in BODY_PARTS\n        assert body_part_2 in BODY_PARTS\n        return (\n            (pl.col(f\"{agent_or_target_1}_x_{body_part_1}\") - pl.col(f\"{agent_or_target_2}_x_{body_part_2}\")).pow(2)\n            + (pl.col(f\"{agent_or_target_1}_y_{body_part_1}\") - pl.col(f\"{agent_or_target_2}_y_{body_part_2}\")).pow(2)\n        ).sqrt() / metadata[\"pix_per_cm_approx\"]\n\n    def body_part_speed(agent_or_target, body_part, period_ms):\n        # # Approximate velocity of the bodypart (cm/s)\n        assert agent_or_target == \"agent\" or agent_or_target == \"target\"\n        assert body_part in BODY_PARTS\n        window_frames = max(1, int(round(period_ms * metadata[\"frames_per_second\"] / 1000.0)))\n        \n        x = pl.col(f\"agent_x_{body_part}\").cast(pl.Float32)\n        y = pl.col(f\"agent_y_{body_part}\").cast(pl.Float32)\n    \n        return (\n            ((x.diff()).pow(2) + (y.diff()).pow(2)).sqrt()\n            / metadata[\"pix_per_cm_approx\"]\n            * metadata[\"frames_per_second\"]\n        ).rolling_mean(window_size=window_frames, center=True)\n        \n    def elongation(agent_or_target):\n        assert agent_or_target == \"agent\" or agent_or_target == \"target\"\n        d1 = body_parts_distance(agent_or_target, \"nose\", agent_or_target, \"tail_base\")\n        d2 = body_parts_distance(agent_or_target, \"ear_left\", agent_or_target, \"ear_right\")\n        return d1 / (d2 + 1e-06)\n\n    def body_angle(agent_or_target):\n        assert agent_or_target == \"agent\" or agent_or_target == \"target\"\n        v1x = pl.col(f\"{agent_or_target}_x_nose\") - pl.col(f\"{agent_or_target}_x_body_center\")\n        v1y = pl.col(f\"{agent_or_target}_y_nose\") - pl.col(f\"{agent_or_target}_y_body_center\")\n        v2x = pl.col(f\"{agent_or_target}_x_tail_base\") - pl.col(f\"{agent_or_target}_x_body_center\")\n        v2y = pl.col(f\"{agent_or_target}_y_tail_base\") - pl.col(f\"{agent_or_target}_y_body_center\")\n        return (v1x * v2x + v1y * v2y) / ((v1x.pow(2) + v1y.pow(2)).sqrt() * (v2x.pow(2) + v2y.pow(2)).sqrt() + 1e-06)\n\n    n_mice = (\n        (metadata[\"mouse1_strain\"] is not None)\n        + (metadata[\"mouse2_strain\"] is not None)\n        + (metadata[\"mouse3_strain\"] is not None)\n        + (metadata[\"mouse4_strain\"] is not None)\n    )\n    start_frame = tracking.select(pl.col(\"video_frame\").min()).item()\n    end_frame = tracking.select(pl.col(\"video_frame\").max()).item()\n\n    result = []\n\n    pivot = tracking.pivot(\n        on=[\"bodypart\"],\n        index=[\"video_frame\", \"mouse_id\"],\n        values=[\"x\", \"y\"],\n    ).sort([\"mouse_id\", \"video_frame\"])\n    # pivot_trackings = {mouse_id: pivot.filter(pl.col(\"mouse_id\") == mouse_id) for mouse_id in range(1, n_mice + 1)}\n\n    pivot_trackings = {}\n\n    for mouse_id in range(1, n_mice + 1):\n        df_mouse = pivot.filter(pl.col(\"mouse_id\") == mouse_id)\n        df_mouse_clean = clean_outliers_polars(df_mouse, dist_thresh=17.0)\n        pivot_trackings[mouse_id] = df_mouse_clean\n        \n    for agent_mouse_id, target_mouse_id in itertools.permutations(range(1, n_mice + 1), 2):\n        result_element = pl.DataFrame(\n            {\n                \"video_id\": metadata[\"video_id\"],\n                \"agent_mouse_id\": agent_mouse_id,\n                \"target_mouse_id\": target_mouse_id,\n                \"video_frame\": pl.arange(start_frame, end_frame + 1, eager=True),\n            },\n            schema={\n                \"video_id\": pl.Int32,\n                \"agent_mouse_id\": pl.Int8,\n                \"target_mouse_id\": pl.Int8,\n                \"video_frame\": pl.Int32,\n            },\n        )\n\n        merged_pivot = (\n            pivot_trackings[agent_mouse_id]\n            .select(\n                pl.col(\"video_frame\"),\n                pl.exclude(\"video_frame\").name.prefix(\"agent_\"),\n            )\n            .join(\n                pivot_trackings[target_mouse_id].select(\n                    pl.col(\"video_frame\"),\n                    pl.exclude(\"video_frame\").name.prefix(\"target_\"),\n                ),\n                on=\"video_frame\",\n                how=\"inner\",\n            )\n            .with_columns(\n                pl.from_epoch(\n                    pl.col(\"video_frame\").truediv(metadata[\"frames_per_second\"]).mul(1_000_000),\n                    time_unit=\"us\",\n                ).alias(\"timestamp\"),\n            )\n        )\n        columns = merged_pivot.columns\n        merged_pivot = merged_pivot.with_columns(\n            *[pl.lit(None).cast(pl.Float32).alias(f\"agent_x_{bp}\") for bp in BODY_PARTS if f\"agent_x_{bp}\" not in columns],\n            *[pl.lit(None).cast(pl.Float32).alias(f\"agent_y_{bp}\") for bp in BODY_PARTS if f\"agent_y_{bp}\" not in columns],\n            *[pl.lit(None).cast(pl.Float32).alias(f\"target_x_{bp}\") for bp in BODY_PARTS if f\"target_x_{bp}\" not in columns],\n            *[pl.lit(None).cast(pl.Float32).alias(f\"target_y_{bp}\") for bp in BODY_PARTS if f\"target_y_{bp}\" not in columns],\n        )\n\n        features = merged_pivot.with_columns(\n            pl.lit(agent_mouse_id).alias(\"agent_mouse_id\"),\n            pl.lit(target_mouse_id).alias(\"target_mouse_id\"),\n        ).select(\n            pl.col(\"video_frame\"),\n            pl.col(\"agent_mouse_id\"),\n            pl.col(\"target_mouse_id\"),\n            *[\n                body_parts_distance(\"agent\", agent_body_part, \"target\", target_body_part).alias(\n                    f\"at__{agent_body_part}__{target_body_part}__distance\"\n                )\n                for agent_body_part, target_body_part in itertools.product(BODY_PARTS, repeat=2)\n            ],\n            *[\n                body_part_speed(\"agent\", body_part, period_ms).alias(f\"agent__{body_part}__speed_{period_ms}ms\")\n                for body_part, period_ms in itertools.product([\"ear_left\", \"ear_right\", \"tail_base\"], [500, 1000, 2000])\n            ],\n            *[\n                body_part_speed(\"target\", body_part, period_ms).alias(f\"target__{body_part}__speed_{period_ms}ms\")\n                for body_part, period_ms in itertools.product([\"ear_left\", \"ear_right\", \"tail_base\"], [500, 1000, 2000])\n            ],\n            elongation(\"agent\").alias(\"agent__elongation\"),\n            elongation(\"target\").alias(\"target__elongation\"),\n            body_angle(\"agent\").alias(\"agent__body_angle\"),\n            body_angle(\"target\").alias(\"target__body_angle\"),\n        )\n\n        result_element = result_element.join(\n            features,\n            on=[\"video_frame\", \"agent_mouse_id\", \"target_mouse_id\"],\n            how=\"left\",\n        )\n        result.append(result_element)\n\n    return pl.concat(result, how=\"vertical\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:09:39.954304Z","iopub.execute_input":"2025-11-24T14:09:39.954491Z","iopub.status.idle":"2025-11-24T14:09:39.971194Z","shell.execute_reply.started":"2025-11-24T14:09:39.954476Z","shell.execute_reply":"2025-11-24T14:09:39.970596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%run -i self_features.py\n%run -i pair_features.py\n\ndef process_video(row):\n    \"\"\"Process a single video to extract self and pair features.\"\"\"\n    lab_id = row[\"lab_id\"]\n    video_id = row[\"video_id\"]\n\n    tracking_path = TRAIN_TRACKING_DIR / f\"{lab_id}/{video_id}.parquet\"\n    tracking = pl.read_parquet(tracking_path)\n\n    self_features = make_self_features(metadata=row, tracking=tracking)\n    pair_features = make_pair_features(metadata=row, tracking=tracking)\n\n    self_features.write_parquet(WORKING_DIR / \"self_features\" / f\"{video_id}.parquet\")\n    pair_features.write_parquet(WORKING_DIR / \"pair_features\" / f\"{video_id}.parquet\")\n\n    return video_id\n\n\n# make data\n(WORKING_DIR / \"self_features\").mkdir(exist_ok=True, parents=True)\n(WORKING_DIR / \"pair_features\").mkdir(exist_ok=True, parents=True)\n\nrows = list(train_dataframe.filter(pl.col(\"behaviors_labeled\").is_not_null()).rows(named=True))\nresults = joblib.Parallel(n_jobs=-1, verbose=5)(joblib.delayed(process_video)(row) for row in rows) # 特徴量生成\nprint(f\"Processed {len(results)} videos successfully\")\n\ndel rows, results\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:09:39.972068Z","iopub.execute_input":"2025-11-24T14:09:39.972334Z","iopub.status.idle":"2025-11-24T14:13:52.533166Z","shell.execute_reply.started":"2025-11-24T14:09:39.972311Z","shell.execute_reply":"2025-11-24T14:13:52.532413Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def tune_threshold(oof_action, y_action):\n    thresholds = np.arange(0, 1.005, 0.005)\n    scores = [f1_score(y_action, (oof_action >= th), zero_division=0) for th in thresholds]\n    best_idx = np.argmax(scores)\n    return thresholds[best_idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:13:52.533999Z","iopub.execute_input":"2025-11-24T14:13:52.534194Z","iopub.status.idle":"2025-11-24T14:13:52.538620Z","shell.execute_reply.started":"2025-11-24T14:13:52.534180Z","shell.execute_reply":"2025-11-24T14:13:52.537794Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_validate(lab_id: str, behavior: str, indices: pl.DataFrame, features: pl.DataFrame, labels: pl.Series):\n    result_dir = WORKING_DIR / \"results\" / lab_id / behavior\n    result_dir.mkdir(exist_ok=True, parents=True)\n\n    if labels.sum() == 0:\n        with open(result_dir / \"f1.txt\", \"w\") as f:\n            f.write(\"0.0\\n\")\n        oof_prediction_dataframe = indices.with_columns(\n            pl.Series(\"fold\", [-1] * len(labels), dtype=pl.Int8),\n            pl.Series(\"prediction\", [0.0] * len(labels), dtype=pl.Float32),\n            pl.Series(\"predicted_label\", [0] * len(labels), dtype=pl.Int8),\n        )\n        oof_prediction_dataframe.write_parquet(result_dir / \"oof_predictions.parquet\")\n        return 0.0\n\n    folds = np.ones(len(labels), dtype=np.int8) * -1\n    oof_predictions = np.zeros(len(labels), dtype=np.float32)\n    oof_prediction_labels = np.zeros(len(labels), dtype=np.int8)\n\n    for fold, (train_idx, valid_idx) in enumerate(\n        StratifiedGroupKFold(n_splits=3, shuffle=True, random_state=42).split(\n            X=features,\n            y=labels,\n            groups=indices.get_column(\"video_id\"),\n        )\n    ):\n        result_dir_fold = result_dir / f\"fold_{fold}\"\n        result_dir_fold.mkdir(exist_ok=True, parents=True)\n\n        X_train = features[train_idx]\n        y_train = labels[train_idx]\n        X_valid = features[valid_idx]\n        y_valid = labels[valid_idx]\n\n        scale_pos_weight = (len(y_train) - y_train.sum()) / y_train.sum()\n\n        params = {\n            \"objective\": \"binary:logistic\",\n            \"eval_metric\": \"logloss\",\n            \"device\": \"cpu\",\n            \"tree_method\": \"hist\",\n            \"learning_rate\": 0.05,\n            \"max_depth\": 6,\n            \"min_child_weight\": 5,\n            \"subsample\": 0.8,\n            \"colsample_bytree\": 0.8,\n            \"scale_pos_weight\": scale_pos_weight,\n            \"max_bin\": 64,\n            \"seed\": 42,\n        }\n        dtrain = xgb.QuantileDMatrix(X_train, label=y_train, feature_names=features.columns, max_bin=64)\n        dvalid = xgb.DMatrix(X_valid, label=y_valid, feature_names=features.columns)\n\n        evals_result = {}\n        early_stopping_callback = xgb.callback.EarlyStopping(\n            rounds=10,\n            metric_name=\"logloss\",\n            data_name=\"valid\",\n            maximize=False,\n            save_best=True,\n        )\n        model = xgb.train(\n            params,\n            dtrain=dtrain,\n            num_boost_round=250,\n            evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n            callbacks=[early_stopping_callback],\n            evals_result=evals_result,\n            verbose_eval=0,\n        )\n\n        fold_predictions = model.predict(dvalid)\n\n        threshold = tune_threshold(fold_predictions, y_valid)\n        folds[valid_idx] = fold\n        oof_predictions[valid_idx] = fold_predictions\n        oof_prediction_labels[valid_idx] = (fold_predictions >= threshold).astype(np.int8)\n\n        # save results\n        model.save_model(result_dir_fold / \"model.json\")\n        with open(result_dir_fold / \"threshold.txt\", \"w\") as f:\n            f.write(f\"{threshold}\\n\")\n\n        xgb.plot_importance(model, max_num_features=20, importance_type=\"gain\", values_format=\"{v:.2f}\")\n        plt.tight_layout()\n        plt.savefig(result_dir_fold / \"feature_importance.png\")\n        plt.close()\n\n        lgb.plot_metric(evals_result, metric=\"logloss\")\n        plt.tight_layout()\n        plt.savefig(result_dir_fold / \"metric.png\")\n        plt.close()\n\n        gc.collect()\n\n    oof_prediction_dataframe = indices.with_columns(\n        pl.Series(\"fold\", folds, dtype=pl.Int8),\n        pl.Series(\"prediction\", oof_predictions, dtype=pl.Float32),\n        pl.Series(\"predicted_label\", oof_prediction_labels, dtype=pl.Int8),\n    )\n    f1 = f1_score(labels, oof_prediction_labels, zero_division=0)\n    with open(result_dir / \"f1.txt\", \"w\") as f:\n        f.write(f\"{f1}\\n\")\n\n    oof_prediction_dataframe.write_parquet(result_dir / \"oof_predictions.parquet\")\n\n        \n    return f1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:13:52.539369Z","iopub.execute_input":"2025-11-24T14:13:52.539622Z","iopub.status.idle":"2025-11-24T14:13:52.554822Z","shell.execute_reply.started":"2025-11-24T14:13:52.539601Z","shell.execute_reply":"2025-11-24T14:13:52.554156Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nself features\n\"\"\"\ngroups = train_self_behavior_dataframe.group_by(\"lab_id\", \"behavior\", maintain_order=True)\ntotal_groups = len(list(groups))\nstart_time = time.perf_counter()\n\nfor idx, ((lab_id, behavior), group) in tqdm(enumerate(groups), total=total_groups):\n    if idx == 0:\n        tqdm.write(\n            f\"|{'LAB':^25}|{'BEHAVIOR':^15}|{'SAMPLES':^10}|{'POSITIVE':^10}|{'FEATURES':^10}|{'F1':^10}|{'ELAPSED TIME':^15}|\",\n            end=\"\\n\",\n        )\n\n    tqdm.write(f\"|{lab_id:^25}|{behavior:^15}|\", end=\"\")\n    index_list = []\n    feature_list = []\n    label_list = []\n\n    # Each data \n    for row in group.rows(named=True):\n        video_id = row[\"video_id\"]\n        agent = row[\"agent\"]\n\n        agent_mouse_id = int(re.search(r\"mouse(\\d+)\", agent).group(1))\n\n        data = pl.scan_parquet(WORKING_DIR / \"self_features\" / f\"{video_id}.parquet\").filter(\n            (pl.col(\"agent_mouse_id\") == agent_mouse_id)\n        )\n        index = data.select(INDEX_COLS).collect(engine=\"streaming\")\n        feature = data.select(pl.exclude(INDEX_COLS)).collect(engine=\"streaming\")\n\n        # read annotation\n        annotation_path = TRAIN_ANNOTATION_DIR / lab_id / f\"{video_id}.parquet\"\n        if annotation_path.exists():\n            annotation = (\n                pl.scan_parquet(annotation_path)\n                .filter((pl.col(\"action\") == behavior) & (pl.col(\"agent_id\") == agent_mouse_id))\n                .collect()\n            )\n        else:\n            annotation = pl.DataFrame(\n                schema={\n                    \"agent_id\": pl.Int8,\n                    \"target_id\": pl.Int8,\n                    \"action\": str,\n                    \"start_frame\": pl.Int16,\n                    \"stop_frame\": pl.Int16,\n                }\n            )\n\n        label_frames = set()\n        for annotation_row in annotation.rows(named=True):\n            label_frames.update(range(annotation_row[\"start_frame\"], annotation_row[\"stop_frame\"]))\n        label = index.select(pl.col(\"video_frame\").is_in(label_frames).cast(pl.Int8).alias(\"label\"))\n\n        if label.get_column(\"label\").sum() == 0:\n            continue\n\n        index_list.append(index)\n        feature_list.append(feature)\n        label_list.append(label.get_column(\"label\"))\n\n    if not index_list:\n        elapsed_time = datetime.timedelta(seconds=int(time.perf_counter() - start_time))\n        tqdm.write(f\"{0:>10,}|{0:>10,}|{0:>10,}|{'-':>10}|{str(elapsed_time):>15}|\", end=\"\\n\")\n        continue\n\n    indices = pl.concat(index_list, how=\"vertical\")\n    features = pl.concat(feature_list, how=\"vertical\")\n    labels = pl.concat(label_list, how=\"vertical\")\n\n    del index_list, feature_list, label_list\n    gc.collect()\n\n    tqdm.write(f\"{len(indices):>10,}|{labels.sum():>10,}|{len(features.columns):>10,}|\", end=\"\")\n\n    f1 = train_validate(lab_id, behavior, indices, features, labels)\n    tqdm.write(f\"{f1:>10.2f}|\", end=\"\")\n\n    elapsed_time = datetime.timedelta(seconds=int(time.perf_counter() - start_time))\n    tqdm.write(f\"{str(elapsed_time):>15}|\", end=\"\\n\")\n\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:13:52.555540Z","iopub.execute_input":"2025-11-24T14:13:52.555740Z","iopub.status.idle":"2025-11-24T14:33:17.447801Z","shell.execute_reply.started":"2025-11-24T14:13:52.555725Z","shell.execute_reply":"2025-11-24T14:33:17.446174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\npair features\n\"\"\"\ngroups = train_pair_behavior_dataframe.group_by(\"lab_id\", \"behavior\", maintain_order=True)\ntotal_groups = len(list(groups))\nstart_time = time.perf_counter()\n\nfor idx, ((lab_id, behavior), group) in tqdm(enumerate(groups), total=total_groups):\n    if idx == 0:\n        tqdm.write(\n            f\"|{'LAB':^25}|{'BEHAVIOR':^15}|{'SAMPLES':^10}|{'POSITIVE':^10}|{'FEATURES':^10}|{'F1':^10}|{'ELAPSED TIME':^15}|\",\n            end=\"\\n\",\n        )\n\n    tqdm.write(f\"|{lab_id:^25}|{behavior:^15}|\", end=\"\")\n    index_list = []\n    feature_list = []\n    label_list = []\n\n    for row in group.rows(named=True):\n        video_id = row[\"video_id\"]\n        agent = row[\"agent\"]\n        target = row[\"target\"]\n\n        agent_mouse_id = int(re.search(r\"mouse(\\d+)\", agent).group(1))\n        target_mouse_id = int(re.search(r\"mouse(\\d+)\", target).group(1))\n\n        data = pl.scan_parquet(WORKING_DIR / \"pair_features\" / f\"{video_id}.parquet\").filter(\n            (pl.col(\"agent_mouse_id\") == agent_mouse_id) & (pl.col(\"target_mouse_id\") == target_mouse_id)\n        )\n        index = data.select(INDEX_COLS).collect(engine=\"streaming\")\n        feature = data.select(pl.exclude(INDEX_COLS)).collect(engine=\"streaming\")\n\n        # read annotation\n        annotation_path = TRAIN_ANNOTATION_DIR / lab_id / f\"{video_id}.parquet\"\n        if annotation_path.exists():\n            annotation = (\n                pl.scan_parquet(annotation_path)\n                .filter(\n                    (pl.col(\"action\") == behavior)\n                    & (pl.col(\"agent_id\") == agent_mouse_id)\n                    & (pl.col(\"target_id\") == target_mouse_id)\n                )\n                .collect()\n            )\n        else:\n            annotation = pl.DataFrame(\n                schema={\n                    \"agent_id\": pl.Int8,\n                    \"target_id\": pl.Int8,\n                    \"action\": str,\n                    \"start_frame\": pl.Int16,\n                    \"stop_frame\": pl.Int16,\n                }\n            )\n\n        label_frames = set()\n        for annotation_row in annotation.rows(named=True):\n            label_frames.update(range(annotation_row[\"start_frame\"], annotation_row[\"stop_frame\"]))\n        label = index.select(pl.col(\"video_frame\").is_in(label_frames).cast(pl.Int8).alias(\"label\"))\n\n        if label.get_column(\"label\").sum() == 0:\n            continue\n\n        index_list.append(index)\n        feature_list.append(feature)\n        label_list.append(label.get_column(\"label\"))\n\n    if not index_list:\n        elapsed_time = datetime.timedelta(seconds=int(time.perf_counter() - start_time))\n        tqdm.write(f\"{0:>10,}|{0:>10,}|{0:>10,}|{'-':>10}|{str(elapsed_time):>15}|\", end=\"\\n\")\n        continue\n\n    indices = pl.concat(index_list, how=\"vertical\")\n    features = pl.concat(feature_list, how=\"vertical\")\n    labels = pl.concat(label_list, how=\"vertical\")\n\n    del index_list, feature_list, label_list\n    gc.collect()\n\n    tqdm.write(f\"{len(indices):>10,}|{labels.sum():>10,}|{len(features.columns):>10,}|\", end=\"\")\n\n    f1 = train_validate(lab_id, behavior, indices, features, labels)\n    tqdm.write(f\"{f1:>10.2f}|\", end=\"\")\n\n    elapsed_time = datetime.timedelta(seconds=int(time.perf_counter() - start_time))\n    tqdm.write(f\"{str(elapsed_time):>15}|\", end=\"\\n\")\n\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:33:17.448357Z","iopub.status.idle":"2025-11-24T14:33:17.448585Z","shell.execute_reply.started":"2025-11-24T14:33:17.448466Z","shell.execute_reply":"2025-11-24T14:33:17.448475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile robustify.py\n\ndef robustify(submission: pl.DataFrame, dataset: pl.DataFrame, train_test: str = \"train\"):\n    traintest_directory = INPUT_DIR / f\"{train_test}_tracking\"\n\n    old_submission = submission.clone()\n    submission = submission.filter(pl.col(\"start_frame\") < pl.col(\"stop_frame\"))\n    if len(submission) != len(old_submission):\n        print(\"ERROR: Dropped frames with start >= stop\")\n\n    old_submission = submission.clone()\n    group_list = []\n    for _, group in submission.group_by(\"video_id\", \"agent_id\", \"target_id\"):\n        group = group.sort(\"start_frame\")\n        mask = np.ones(len(group), dtype=bool)\n        last_stop_frame = 0\n        for i, row in enumerate(group.rows(named=True)):\n            if row[\"start_frame\"] < last_stop_frame:\n                mask[i] = False\n            else:\n                last_stop_frame = row[\"stop_frame\"]\n        group_list.append(group.filter(pl.Series(\"mask\", mask)))\n\n    submission = pl.concat(group_list)\n\n    if len(submission) != len(old_submission):\n        print(\"ERROR: Dropped duplicate frames\")\n\n    s_list = []\n    for row in dataset.rows(named=True):\n        lab_id = row[\"lab_id\"]\n        video_id = row[\"video_id\"]\n        if row[\"behaviors_labeled\"] is None:\n            continue\n\n        if video_id in submission.get_column(\"video_id\").to_list():\n            continue\n\n        if isinstance(row[\"behaviors_labeled\"], str):\n            continue\n\n        print(f\"Video {video_id} has no predictions.\")\n\n        path = traintest_directory / f\"/{lab_id}/{video_id}.parquet\"\n        vid = pd.read_parquet(path)\n\n        vid_behaviors = json.loads(row[\"behaviors_labeled\"])\n        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n        vid_behaviors = [b.split(\",\") for b in vid_behaviors]\n        vid_behaviors = pd.DataFrame(vid_behaviors, columns=[\"agent\", \"target\", \"action\"])\n\n        start_frame = vid.video_frame.min()\n        stop_frame = vid.video_frame.max() + 1\n\n        for (agent, target), actions in vid_behaviors.groupby([\"agent\", \"target\"]):\n            batch_length = int(np.ceil((stop_frame - start_frame) / len(actions)))\n            for i, action_row in enumerate(actions.itertuples(index=False)):\n                batch_start = start_frame + i * batch_length\n                batch_stop = min(batch_start + batch_length, stop_frame)\n                s_list.append((video_id, agent, target, action_row[\"action\"], batch_start, batch_stop))\n\n    if len(s_list) > 0:\n        submission = pd.concat(\n            [\n                submission,\n                pd.DataFrame(s_list, columns=[\"video_id\", \"agent_id\", \"target_id\", \"action\", \"start_frame\", \"stop_frame\"]),\n            ]\n        )\n        print(\"ERROR: Filled empty videos\")\n\n    return submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:33:17.449367Z","iopub.status.idle":"2025-11-24T14:33:17.449987Z","shell.execute_reply.started":"2025-11-24T14:33:17.449803Z","shell.execute_reply":"2025-11-24T14:33:17.449819Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"group_oof_predictions = []\ngroups = train_behavior_dataframe.group_by(\"lab_id\", \"video_id\", \"agent\", \"target\", maintain_order=True)\n\nfor (lab_id, video_id, agent, target), group in tqdm(groups, total=len(list(groups))):\n    agent_mouse_id = int(re.search(r\"mouse(\\d+)\", agent).group(1))\n    target_mouse_id = -1 if target == \"self\" else int(re.search(r\"mouse(\\d+)\", target).group(1))\n\n    prediction_dataframe_list = []\n\n    for row in group.rows(named=True):\n        behavior = row[\"behavior\"]\n\n        oof_path = WORKING_DIR / \"results\" / lab_id / behavior / \"oof_predictions.parquet\"\n        if not oof_path.exists():\n            continue\n\n        prediction = (\n            pl.scan_parquet(oof_path)\n            .filter(\n                (pl.col(\"video_id\") == video_id)\n                & (pl.col(\"agent_mouse_id\") == agent_mouse_id)\n                & (pl.col(\"target_mouse_id\") == target_mouse_id)\n            )\n            .select(*INDEX_COLS, (pl.col(\"prediction\") * pl.col(\"predicted_label\")).alias(behavior))\n            .collect()\n        )\n\n        if len(prediction) == 0:\n            continue\n\n        prediction_dataframe_list.append(prediction)\n\n    if not prediction_dataframe_list:\n        continue\n\n    prediction_dataframe = pl.concat(prediction_dataframe_list, how=\"align\")\n\n    cols = prediction_dataframe.select(pl.exclude(INDEX_COLS)).columns\n    prediction_labels_dataframe = prediction_dataframe.with_columns(\n        pl.struct(pl.exclude(INDEX_COLS))\n        .map_elements(\n            lambda row: \"none\" if sum(row.values()) == 0 else (cols[np.argmax(list(row.values()))]),\n            return_dtype=pl.String,\n        )\n        .alias(\"prediction\")\n    ).select(INDEX_COLS + [\"prediction\"])\n\n    group_oof_prediction = (\n        prediction_labels_dataframe.filter((pl.col(\"prediction\") != pl.col(\"prediction\").shift(1)))\n        .with_columns(pl.col(\"video_frame\").shift(-1).alias(\"stop_frame\"))\n        .filter(pl.col(\"prediction\") != \"none\")\n        .select(\n            pl.col(\"video_id\"),\n            (\"mouse\" + pl.col(\"agent_mouse_id\").cast(str)).alias(\"agent_id\"),\n            pl.when(pl.col(\"target_mouse_id\") == -1)\n            .then(pl.lit(\"self\"))\n            .otherwise(\"mouse\" + pl.col(\"target_mouse_id\").cast(str))\n            .alias(\"target_id\"),\n            pl.col(\"prediction\").alias(\"action\"),\n            pl.col(\"video_frame\").alias(\"start_frame\"),\n            pl.col(\"stop_frame\"),\n        )\n    )\n\n    group_oof_predictions.append(group_oof_prediction)\n\n%run -i robustify.py\n\noof_predictions = pl.concat(group_oof_predictions, how=\"vertical\")\noof_predictions = robustify(oof_predictions, train_dataframe, train_test=\"train\")\noof_predictions.with_row_index(\"row_id\").write_csv(WORKING_DIR / \"oof_predictions.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:33:17.450730Z","iopub.status.idle":"2025-11-24T14:33:17.451046Z","shell.execute_reply.started":"2025-11-24T14:33:17.450917Z","shell.execute_reply":"2025-11-24T14:33:17.450929Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_validation_metrics(submission, verbose=True):\n    \"\"\"Compute and display validation metrics for single vs pair behaviors.\"\"\"\n    # solution_df\n    dataset = pl.read_csv(INPUT_DIR / \"train.csv\").to_pandas()\n\n    solution = []\n    for _, row in dataset.iterrows():\n        lab_id = row[\"lab_id\"]\n        if lab_id.startswith(\"MABe22\"):\n            continue\n\n        video_id = row[\"video_id\"]\n        path = TRAIN_ANNOTATION_DIR / lab_id / f\"{video_id}.parquet\"\n        try:\n            annot = pd.read_parquet(path)\n        except FileNotFoundError:\n            continue\n\n        annot[\"lab_id\"] = lab_id\n        annot[\"video_id\"] = video_id\n        annot[\"behaviors_labeled\"] = row[\"behaviors_labeled\"]\n        annot[\"target_id\"] = np.where(\n            annot.target_id != annot.agent_id, annot[\"target_id\"].apply(lambda s: f\"mouse{s}\"), \"self\"\n        )\n        annot[\"agent_id\"] = annot[\"agent_id\"].apply(lambda s: f\"mouse{s}\")\n        solution.append(annot)\n\n    solution = pd.concat(solution)\n\n    try:\n        # Separate single and pair behaviors\n        submission_single = submission[submission[\"target_id\"] == \"self\"].copy()\n        submission_pair = submission[submission[\"target_id\"] != \"self\"].copy()\n\n        # Filter solution to match submission videos\n        solution_videos = set(submission[\"video_id\"].unique())\n        solution = solution[solution[\"video_id\"].isin(solution_videos)]\n\n        if len(solution) == 0:\n            return\n\n        # Compute overall F1 score\n        overall_f1 = score(solution, submission, \"row_id\", beta=1.0)\n        print(f\"\\n{'=' * 60}\")\n        print(\"PERFORMANCE METRICS\")\n        print(f\"{'=' * 60}\")\n        print(f\"Overall F1 Score: {overall_f1:.4f}\")\n        print(f\"Total predictions: {len(submission)}\")\n        print(f\"  - Single behaviors: {len(submission_single)}\")\n        print(f\"  - Pair behaviors: {len(submission_pair)}\")\n\n        # Compute per-action F1 scores using existing scoring function\n        solution_pl = pl.DataFrame(solution)\n        submission_pl = pl.DataFrame(submission)\n\n        # Add label_key and prediction_key\n        solution_pl = solution_pl.with_columns(\n            pl.concat_str(\n                [\n                    pl.col(\"video_id\").cast(pl.Utf8),\n                    pl.col(\"agent_id\").cast(pl.Utf8),\n                    pl.col(\"target_id\").cast(pl.Utf8),\n                    pl.col(\"action\"),\n                ],\n                separator=\"_\",\n            ).alias(\"label_key\"),\n        )\n        submission_pl = submission_pl.with_columns(\n            pl.concat_str(\n                [\n                    pl.col(\"video_id\").cast(pl.Utf8),\n                    pl.col(\"agent_id\").cast(pl.Utf8),\n                    pl.col(\"target_id\").cast(pl.Utf8),\n                    pl.col(\"action\"),\n                ],\n                separator=\"_\",\n            ).alias(\"prediction_key\"),\n        )\n\n        # Group by action and compute metrics\n        action_stats = defaultdict(lambda: {\"single\": {\"count\": 0, \"f1\": 0.0}, \"pair\": {\"count\": 0, \"f1\": 0.0}})\n\n        for lab in solution_pl[\"lab_id\"].unique():\n            lab_solution = solution_pl.filter(pl.col(\"lab_id\") == lab).clone()\n            lab_videos = set(lab_solution[\"video_id\"].unique())\n            lab_submission = submission_pl.filter(pl.col(\"video_id\").is_in(lab_videos)).clone()\n\n            # Compute per-action F1 using same logic as single_lab_f1\n            label_frames = defaultdict(set)\n            prediction_frames = defaultdict(set)\n\n            for row in lab_solution.to_dicts():\n                label_frames[row[\"label_key\"]].update(range(row[\"start_frame\"], row[\"stop_frame\"]))\n\n            for row in lab_submission.to_dicts():\n                key = row[\"prediction_key\"]\n                prediction_frames[key].update(range(row[\"start_frame\"], row[\"stop_frame\"]))\n\n            for key in set(list(label_frames.keys()) + list(prediction_frames.keys())):\n                action = key.split(\"_\")[-1]\n                mode = \"single\" if \"self\" in key else \"pair\"\n\n                pred_frames = prediction_frames.get(key, set())\n                label_frames_set = label_frames.get(key, set())\n\n                tp = len(pred_frames & label_frames_set)\n                fn = len(label_frames_set - pred_frames)\n                fp = len(pred_frames - label_frames_set)\n\n                if tp + fn + fp > 0:\n                    f1 = (1 + 1**2) * tp / ((1 + 1**2) * tp + 1**2 * fn + fp)\n                    action_stats[action][mode][\"count\"] += 1\n                    action_stats[action][mode][\"f1\"] += f1\n\n        # Print per-action summary\n        print(\"\\nPer-Action Performance Summary:\")\n        print(f\"{'-' * 60}\")\n        print(f\"{'Action':<20} {'Mode':<10} {'Count':<10} {'Avg F1':<10}\")\n        print(f\"{'-' * 60}\")\n\n        for action in sorted(action_stats.keys()):\n            for mode in [\"single\", \"pair\"]:\n                stats = action_stats[action][mode]\n                if stats[\"count\"] > 0:\n                    avg_f1 = stats[\"f1\"] / stats[\"count\"]\n                    print(f\"{action:<20} {mode:<10} {stats['count']:<10} {avg_f1:<10.4f}\")\n\n        # Summary by mode\n        single_actions = [a for a in action_stats.keys() if action_stats[a][\"single\"][\"count\"] > 0]\n        pair_actions = [a for a in action_stats.keys() if action_stats[a][\"pair\"][\"count\"] > 0]\n\n        if single_actions:\n            single_avg_f1 = np.mean(\n                [\n                    action_stats[a][\"single\"][\"f1\"] / action_stats[a][\"single\"][\"count\"]\n                    for a in single_actions\n                    if action_stats[a][\"single\"][\"count\"] > 0\n                ]\n            )\n            print(f\"\\nSingle behaviors: {len(single_actions)} actions, Avg F1: {single_avg_f1:.4f}\")\n\n        if pair_actions:\n            pair_avg_f1 = np.mean(\n                [\n                    action_stats[a][\"pair\"][\"f1\"] / action_stats[a][\"pair\"][\"count\"]\n                    for a in pair_actions\n                    if action_stats[a][\"pair\"][\"count\"] > 0\n                ]\n            )\n            print(f\"Pair behaviors: {len(pair_actions)} actions, Avg F1: {pair_avg_f1:.4f}\")\n\n        print(f\"{'=' * 60}\\n\")\n\n    except Exception as e:\n        if verbose:\n            error_msg = str(e)\n            if len(error_msg) > 200:\n                error_msg = error_msg[:200] + \"...\"\n            print(f\"\\nWarning: Could not compute validation metrics: {error_msg}\")\n            if verbose:\n                print(f\"Traceback: {traceback.format_exc()[:300]}\")\n\ncompute_validation_metrics(submission=pd.read_csv(WORKING_DIR / \"oof_predictions.csv\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:33:17.452059Z","iopub.status.idle":"2025-11-24T14:33:17.452270Z","shell.execute_reply.started":"2025-11-24T14:33:17.452172Z","shell.execute_reply":"2025-11-24T14:33:17.452180Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"# read data\ntest_dataframe = pl.read_csv(INPUT_DIR / \"test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:33:17.453348Z","iopub.status.idle":"2025-11-24T14:33:17.453601Z","shell.execute_reply.started":"2025-11-24T14:33:17.453470Z","shell.execute_reply":"2025-11-24T14:33:17.453481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# preprocess behavior labels\ntest_behavior_dataframe = (\n    test_dataframe.filter(pl.col(\"behaviors_labeled\").is_not_null())\n    .select(\n        pl.col(\"lab_id\"),\n        pl.col(\"video_id\"),\n        pl.col(\"behaviors_labeled\").map_elements(eval, return_dtype=pl.List(pl.Utf8)).alias(\"behaviors_labeled_list\"),\n    )\n    .explode(\"behaviors_labeled_list\")\n    .rename({\"behaviors_labeled_list\": \"behaviors_labeled_element\"})\n    .select(\n        pl.col(\"lab_id\"),\n        pl.col(\"video_id\"),\n        pl.col(\"behaviors_labeled_element\").str.split(\",\").list[0].str.replace_all(\"'\", \"\").alias(\"agent\"),\n        pl.col(\"behaviors_labeled_element\").str.split(\",\").list[1].str.replace_all(\"'\", \"\").alias(\"target\"),\n        pl.col(\"behaviors_labeled_element\").str.split(\",\").list[2].str.replace_all(\"'\", \"\").alias(\"behavior\"),\n    )\n)\n\ntest_self_behavior_dataframe = test_behavior_dataframe.filter(pl.col(\"behavior\").is_in(SELF_BEHAVIORS))\ntest_pair_behavior_dataframe = test_behavior_dataframe.filter(pl.col(\"behavior\").is_in(PAIR_BEHAVIORS))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:33:17.454646Z","iopub.status.idle":"2025-11-24T14:33:17.454957Z","shell.execute_reply.started":"2025-11-24T14:33:17.454805Z","shell.execute_reply":"2025-11-24T14:33:17.454819Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"(WORKING_DIR / \"self_features\").mkdir(exist_ok=True, parents=True)\n(WORKING_DIR / \"pair_features\").mkdir(exist_ok=True, parents=True)\n\nrows = test_dataframe.rows(named=True)\n\nfor row in tqdm(rows, total=len(rows)):\n    lab_id = row[\"lab_id\"]\n    video_id = row[\"video_id\"]\n\n    tracking_path = TEST_TRACKING_DIR / f\"{lab_id}/{video_id}.parquet\"\n    tracking = pl.read_parquet(tracking_path)\n\n    self_features = make_self_features(metadata=row, tracking=tracking)\n    pair_features = make_pair_features(metadata=row, tracking=tracking)\n\n    self_features.write_parquet(WORKING_DIR / \"self_features\" / f\"{video_id}.parquet\")\n    pair_features.write_parquet(WORKING_DIR / \"pair_features\" / f\"{video_id}.parquet\")\n\n    del self_features, pair_features\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:33:17.456146Z","iopub.status.idle":"2025-11-24T14:33:17.456480Z","shell.execute_reply.started":"2025-11-24T14:33:17.456308Z","shell.execute_reply":"2025-11-24T14:33:17.456322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"group_submissions = []\ngroups = list(test_behavior_dataframe.group_by(\"lab_id\", \"video_id\", \"agent\", \"target\", maintain_order=True))\n\nfor (lab_id, video_id, agent, target), group in tqdm(groups, total=len(list(groups))):\n    agent_mouse_id = int(re.search(r\"mouse(\\d+)\", agent).group(1))\n    target_mouse_id = -1 if target == \"self\" else int(re.search(r\"mouse(\\d+)\", target).group(1))\n\n    if target == \"self\":\n        index = (\n            pl.scan_parquet(WORKING_DIR / \"self_features\" / f\"{video_id}.parquet\")\n            .filter((pl.col(\"agent_mouse_id\") == agent_mouse_id))\n            .select(INDEX_COLS)\n            .collect()\n        )\n        feature = (\n            pl.scan_parquet(WORKING_DIR / \"self_features\" / f\"{video_id}.parquet\")\n            .filter((pl.col(\"agent_mouse_id\") == agent_mouse_id))\n            .select(pl.exclude(INDEX_COLS))\n            .collect()\n        )\n    else:\n        index = (\n            pl.scan_parquet(WORKING_DIR / \"pair_features\" / f\"{video_id}.parquet\")\n            .filter((pl.col(\"agent_mouse_id\") == agent_mouse_id) & (pl.col(\"target_mouse_id\") == target_mouse_id))\n            .select(INDEX_COLS)\n            .collect()\n        )\n        feature = (\n            pl.scan_parquet(WORKING_DIR / \"pair_features\" / f\"{video_id}.parquet\")\n            .filter((pl.col(\"agent_mouse_id\") == agent_mouse_id) & (pl.col(\"target_mouse_id\") == target_mouse_id))\n            .select(pl.exclude(INDEX_COLS))\n            .collect()\n        )\n\n    prediction_dataframe = index.clone()\n\n    for row in group.rows(named=True):\n        behavior = row[\"behavior\"]\n\n        predictions = []\n        prediction_labels = []\n\n        fold_dirs = list((WORKING_DIR / \"results\" / lab_id / behavior).glob(\"fold_*\"))\n        if not fold_dirs:\n            continue\n\n        for fold_dir in fold_dirs:\n            with open(fold_dir / \"threshold.txt\", \"r\") as f:\n                threshold = float(f.read().strip())\n            model = xgb.Booster(model_file=fold_dir / \"model.json\")\n            dtest = xgb.DMatrix(feature, feature_names=feature.columns)\n            fold_predictions = model.predict(dtest)\n            predictions.append(fold_predictions)\n            prediction_labels.append((fold_predictions >= threshold).astype(np.int8))\n\n        prediction_dataframe = prediction_dataframe.with_columns(\n            *[\n                pl.Series(name=f\"{behavior}_{fold}\", values=predictions[fold] * prediction_labels[fold], dtype=pl.Float32)\n                for fold in range(len(fold_dirs))\n            ]\n        )\n\n    cols = prediction_dataframe.select(pl.exclude(INDEX_COLS)).columns\n    if not cols:\n        tqdm.write(f\"Warning: No predictions found for {lab_id}, {video_id}, {agent}, {target}\")\n        continue\n\n    prediction_labels_dataframe = prediction_dataframe.with_columns(\n        pl.struct(pl.col(cols))\n        .map_elements(\n            lambda row: \"none\" if sum(row.values()) == 0 else (cols[np.argmax(list(row.values()))]).split(\"_\")[0],\n            return_dtype=pl.String,\n        )\n        .alias(\"prediction\")\n    ).select(INDEX_COLS + [\"prediction\"])\n\n    group_submission = (\n        prediction_labels_dataframe.filter((pl.col(\"prediction\") != pl.col(\"prediction\").shift(1)))\n        .with_columns(pl.col(\"video_frame\").shift(-1).alias(\"stop_frame\"))\n        .filter(pl.col(\"prediction\") != \"none\")\n        .select(\n            pl.col(\"video_id\"),\n            (\"mouse\" + pl.col(\"agent_mouse_id\").cast(str)).alias(\"agent_id\"),\n            pl.when(pl.col(\"target_mouse_id\") == -1)\n            .then(pl.lit(\"self\"))\n            .otherwise(\"mouse\" + pl.col(\"target_mouse_id\").cast(str))\n            .alias(\"target_id\"),\n            pl.col(\"prediction\").alias(\"action\"),\n            pl.col(\"video_frame\").alias(\"start_frame\"),\n            pl.col(\"stop_frame\"),\n        )\n    )\n\n    group_submissions.append(group_submission)\n\nsubmission = pl.concat(group_submissions, how=\"vertical\").sort(\n    \"video_id\",\n    \"agent_id\",\n    \"target_id\",\n    \"action\",\n    \"start_frame\",\n    \"stop_frame\",\n)\nsubmission = robustify(submission, test_dataframe, train_test=\"test\")\nsubmission.with_row_index(\"row_id\").write_csv(WORKING_DIR / \"submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:33:17.457582Z","iopub.status.idle":"2025-11-24T14:33:17.457882Z","shell.execute_reply.started":"2025-11-24T14:33:17.457735Z","shell.execute_reply":"2025-11-24T14:33:17.457748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!head submission.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:33:17.459007Z","iopub.status.idle":"2025-11-24T14:33:17.459325Z","shell.execute_reply.started":"2025-11-24T14:33:17.459170Z","shell.execute_reply":"2025-11-24T14:33:17.459183Z"}},"outputs":[],"execution_count":null}]}